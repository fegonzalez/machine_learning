

##==============================================================================
## INDEX
##==============================================================================

# 1.- Machine Learning models
#
#     1.1 Linear Regression
#     	  1.1.1 Linear Regression basics
# 	  1.1.2 Problem description
#
#     1.2 Logistic Regression
#     	  1.2.1 Logistic Regression basics
# 	  1.2.2 Linear Classifiers
# 	  1.2.3 Decision Boundary: What (classes) can h(x) represent?
# 	  1.2.4 Estimated (class) probabilities: how confident is a prediction?
# 	  1.2.5 Classification Problem description
#     	  1.2.6 Multiclass Classification: one-vs-all algorithm (method)
# 	  1.2.7 Miss-classification error
#
#     1.3 Clustering [2].41-42
#
#     1.4 Recommender Systems
#     	  1.4.1 Building a recommender system
#     	  1.4.2 Collaborative Filtering
#     	  1.4.3 Performance metric for recommender systems
#
#     1.5 Neural Networks
#     	  1.5.1 NN Representation
# 	  1.5.2 NN Learning
# 	  1.5.3 NN as a machine learning predictor  [2].27
#
#     1.6 Deep Learning
#     	  1.6.1 Neural Network model to solve deep learning
# 	  1.6.2 Application of deep learning to computer vision
# 	  1.6.3 Challenges of deep learning 
# 	  1.6.4 Deep Features: deep learning + transfer learning
#
#
#     1.? Dimensionality Reduction [2].43-46
#
#
#     1.? Anomaly Detection  [2].47-53
#     
#
#     1.? Support Vector Machines [2].35-38   NOTICE  Supervised learning model
#
#     1.? Large Scale Machine Learning [2].61-64


# 2.- Supervised Learning Algorithms
#
#     2.1 Gradient Descent Algorithm
#     	   2.1.1 Equation
#     	   2.1.2 Vectorized Notation
#     	   2.1.3 Speeding up Gradient Descent
#     	   2.1.4 Debugging Gradient Descent [2].p7
#     2.2 Backpropagation Algorithm



# 3.- Unsupervised Learning Algorithms
#
#     3.1 k-means algorithm
#     	  3.1.1 k-means for non-separated clusters
# 	  3.1.2 Optimization objective
# 	  3.1.3 Random initialization of the centroids [e1]
# 	  3.1.4 Choosing the number of clusters


# 4.- Auxiliar techniques
#
#     4.1 Feature scaling  
#     4.2 Mean Normalization
#     4.3 Polynomial Regression
#     4.4 Advanced Optimization


# 5.- Regularization (solving the over-fitting problem)
#
#     5.1 Overfitting Problem (high variance)
#     5.2 Underfitting Problem (high bias)
#     5.3 Regularization
#     5.4 Regularized Linear Regression
#     	   5.4.4.1 Vectorized Linear Regression with Regularization
#     5.5 Regularized Normal Equation
#     5.6 Regularized Logistic Regression
#     	   5.4.6.1 Vectorized Logistic Regression with Regularization

# 6.- Advice for applying Machine Learning
#
#     6.1 Is h(x) OK? - evaluating the hypothesis function
#     6.2 Are the data sets OK? - Model selection & train/cv/test sets
#     6.3 Bias/Variance
#     	  6.3.1 Trade-off intuition 
# 	  6.3.2 Is 'd' OK? - Learning curves: 'd' selection
# 	  6.3.3 Is 'm' OK? - Learning curves: 'm' selection
# 	  6.3.4 Is λ OK? - Regularization & Bias/Variance: selecting λ
# 	  6.3.5 The decision process
#     6.4 Neural Networks Diagnosis

# 7.- Machine Learning systems design [2].page33
#
#     7.1 Error analysis
#     7.2 Error metrics for skewed classes: apply the Precision-Recall trade-off
#     7.3 How much data should we train?. Learning curves


# 8.- Some Machine Learning Problems 
#
#     8.1 Document Retrieval: similarity & clustering
#     	  8.1.1 How to measure similarity? - Bag of words model
# 	  8.1.2 Retrieving similar documents


# Hints

# Warnings

# Annex.- Maths Review

# Annex.- Linear Algebra Review

# Glossary 

# References

# Code examples


##==============================================================================

INFO notation   x sub i represented as  'x_i'

INFO notation   x super i represented as  'x^i'

INFO notation	Summation from i=1 to m represented as 'SUM_i=1_to_m'

INFO Notation 	theta can be represented as 'θ' is some equations.

INFO Notation 	h_theta can be represented as 'h' is some equations.

INFO Notation 	in vectorized notation, uppercase means MATRIX & lowercase means
     	      	scalar variable.

INFO Notation   Matrix: A' is the transpose matrix of A

INFO Notation   Matrix: inv(A) is the inverse matrix of A

INFO Notation   A /=> B: A does not implies B 


##==============================================================================
## 1.- Machine Learning models
##==============================================================================

##------------------------------------------------------------------------------
# 1.1 Linear Regression
##------------------------------------------------------------------------------

# 1.1.1 Linear Regression basics


NOTICE  Supervised learning model


a) To predict the actual CONTINUOUS valued output ('y/x' is a Gaussian
   distribution)

b) Multiple Linear Regression:                    y = f(x_1, .., x_n)

c) Simple Linear Regression (one variable l.r.):  y = f(x) ; M.L.R. where n=1


# 1.1.2 Problem description

a) Model representation

   Training set (x, y, m)   ->   i-th training example ( x(i), y(i) )

   m: number of examples
   n: number of features (n=1 in simple linear regression)
   x: inputs
   y: outputs

   X^i: i-th training example input

   X_j^i: i-th training example value of feature j

   Y^i: i-th training example output


b) Problem representation


         training set

             |
	     v

      learning algorithm

             |
	     v

 x  ->  h (hypothesis)  ->  y


c) hypothesis representation

   # simple linear regression (particular case, n=1)

   h_theta(x) = theta_0 + theta_1 * x


   # multiple linear regression (general case)

   h_theta(x) = theta_0 + theta_1 * x + .. + theta_n * x  =
   	      = SUM_i=1_to_n (theta_i * x_i)  ; x_0 = 1 


   INFO h_theta(x) can be notated as h(x) or just h.


d) Cost function 

   cost(h,y) = quadratic error = (h(x) - y)**2
   
   # multiple linear regression
   J(theta) = (1/2m)*cost(h,y) =  (1/2m) SUM_i=1_to_m(h(x^i ) - y^i)**2


e) Schema

   - Hypothesis:	h_theta(x)

   - Parameters:	theta_0, theta_1, .., theta_n

   - Cost Function:	J(theta)

   - Need: find the theta values to minimize J(theta), thus minimize the error
     	   between the real solution (y) and the approximated solution (h)

   - GOAL: use these values in h(x) to predict new solutions to new inputs.


   The Problem we need to solve is:  How to get theta values?

   -> we want software that automatically find theta values that minimize J
      (i.e) Gradient Descent algorithms.


##------------------------------------------------------------------------------
# 1.2. Logistic Regression
##------------------------------------------------------------------------------


NOTICE  Supervised learning model


# 1.2.1 Logistic Regression basics

a) Regression model where the dependent variable (DV) is categorical.

b) Logistic regression predicts the probability of particular outcomes -> to
   predict the actual DISCRETE valued output (i.e. {yes, no})

c) The conditional distribution 'y|x' is a Bernoulli distribution (y ∈ {0,1]),
   rather than a Gaussian distribution.


# 1.2.2 Linear Classifiers

Def Given an input X, a linear classifier IDENTIFY THE CLASS (y) it belongs to
    by making a classification decision based on the value of a LINEAR
    COMBINATION of the features of the input [4.6]

    y = f(θ . X)    # (scalar) dot product

    (i.e. Sentiment Analysis Problems using a Threshold classifier [3.2].p16)
     f(θ . X) >= threshold -> y = 1
     f(θ . X)  < threshold -> y = 0
     

# 1.2.3 Decision Boundary: What (classes) can h(x) represent?

Def A decision boundary is the region of a problem space in which the output
    label of a classifier is ambiguous [4.7]

- Decision boundary separates positive & negative predictions

  For linear classifiers:
   -> line: when 2 weights are non-zero
   -> plane: when 3 weights are non-zero
   -> hyperplane: when many weights are non-zero

  For more general classifiers -> more complicated shapes


HINT  Decicion boundary is a property of 'h_θ(x)',  it is not a property of 'X'

	i)   step 1: get θ	              
	ii)  step 2: get h
	iii) step 3: paint the plot of 'h_θ(x)', for several features of 'x'
	
	-> get the decision boundary (line, plane, ...) that separates positive
           & negative classes


# 1.2.4 Estimated (class) probabilities: how confident is a prediction?

HINT class probabilities are extremely useful in a practice

- Interpretation: h(x) = estimated prob. that y=1 on input x, given θ params.

  		  h(x) = P(y=1/x ; θ)

  Note: y ∈ {0, 1} => P(y=0/x; θ) = 1 - P(y=1/x; θ)
 


# 1.2.5 Classification Problem description

                                   | 0: negative class (non existence of)
a) Problem solution  ≡  y ∈ {0,1} < 
                                   | 1: positive class (existence of)


          | y ∈ {0, 1} : binary classification problem
b) Types < 
          | y ∈ {0, 1, 2, ..} : multiclass c.p.


c) hypothesis representation [2].11

 PROBLEM   h=θ.X is a BAD idea (1.2.1.c): y ∈ {0,1} ∀x  /=>  0 ≤ h(x) ≤ 1
    |
    v
 SOLUTION  h = Sigmoid Function: "g(z) = 1 / (1 +  e**(-z))"   [2].ML.C5, [4.2]

 	   g(z) = 1 / (1 +  e**(-z))   (1)

                            | ∈ [0, 0.5) if z<0
	   g(z) ∈ [0, 1] = <  0.5        if z=0     THRESHOLD
                            | ∈ (0.5, 1] if z>0


           h_θ(x) = g(θ'x) = 1/(1+e(-(θ'x)))


                         | 1  if g(z) ≥ THRESHOLD) iff z≥0
	   => h_θ(x) =  < 
                         | 0  otherwise



HINT Logistic Regression Cost Function (sigma) is convex => Gradient Descent
     algorithm ALWAYS converge to GLOBAL minimum


WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ

d) Cost function [2].13

PROBLEM sigmoid is not a linear function => many local minimums => linear
       Gradient Descent algorithm is not valid for logistic regression.


                 | -log h(x)  if y=1 |
   cost(h, y) = <                     > =  - y log(h) - (1-y)log(1-h)
                 | -log (1-h) if y=0 |


NOTICE linear vs logistic regression: the difference is only in h_θ(x)


    J(0) = (1/m) * cost(h,y)


# 1.2.6 Multiclass Classification: one-vs-all algorithm (method)

- Precondition: k-classes => k-logistic regression classification

- step 1: train a logistic regression classifier 'h_θ^i (x)' for each class
          'i' to predict p(y=i/x;θ)

- step 2: Given an input X, how to make a prediction?
       	  pick the class 'i' / max h_θ^i (x)
                                i

WARNING  ∑(h) > 1  is possible because different classes can intersect.



# 1.2.7 Miss-classification error [2].29

 Classification Error calculation for the test data set (X_test, y_test, m_test)

                    | 1   if ((h>=0.5) ∧ (y==0)) # predicted y=1 but actual y=0
		    |
                    | 1   if ((h<0.5) ∧ (y==1))  # predicted y=0 but actual y=1
  err(h_θ(x), y) = <
                    | 0   otherwise



  error = #mistakes / #total values	 # the best possible is 0
    
  accuracy = #correct / #total values = 1-error	# best possible is 1

  WARNING Accuracy is a bad index to evaluate skewed classes (always high)




##------------------------------------------------------------------------------
# 1.3 Clustering [2].41-42
##------------------------------------------------------------------------------

NOTICE  Unsupervised learning model

def (GOTO Glossary.Clustering)

- Main idea: instances in the same cluster are more similar to each other than
  those in others.

- Cluster analysis itself is not one specific algorithm, but the general task
  to be solved.

- Algorithm: k-means algorithm (GOTO 3.1)

- Problem application: DETECT SIMILARITIES (documents, images, illness, ...) ->
  structured search, product recommendation, grouping, ...

- Work-flow (unsupervised)
  - Training data = table(doc id, doc text)
  - Feature extraction = apply tf-idf(Training data) -> X = tf-idf
  - θ = cluster centers
  - h = estimated cluster label
  - ML model = clustering
  - ML algorithm = k-means
  - Quality metric = distance to cluster centers?



##------------------------------------------------------------------------------
# 1.4 Recommender Systems [3.4] [2].55-59
##------------------------------------------------------------------------------

NOTICE  Supervised learning model

INFO Users & Items are of the same type: recommendation =  (user, item) pair


# 1.4.1 Building a recommender system

a) Solution 0: Popularity [e2]

   - Implementation: rank by GLOBAL popularity

   - Pros: easy

   - Limitations: no personalization -> makes the same prediction for all users

b) Solution 1: Classification model

   - Implementation: prob(user_u-like-produc_p) ?

   - Pros:

     > personalized: uses user info & purchase history

     > Features can capture context: Time of the day, what I just saw,…
     
     > Even handles limited user history: Age of user, …

   - Limitations:

     > Features may not be available

     > Often doesn't’t perform as well as collaborative filtering methods


c) Solution 2: Co-occurrence matrix (user who liked this also liked ...)

   Pros    Personalization
   Limits  No capture context
   

   - Implementation: co-occurrence matrix
     > #items x #items matrix
     > Symmetric: # purchasing i & j same as # for j & i (C_ij = C_ji)
     
   i) Making Recommendations:

      A User liked product ABC, what other products can the system recommend?

      1. Look at ABC row of matrix
      2. Recommend other items with largest counts


   ii) Is a skewed matrix => Normalize co-occurrences: Similarity matrix

       • Jaccard similarity (normalizes by popularity): Who purchased i and j
         divided by who purchased i or j: C_ij = Ci*Cj / Ci+Cj

       • Many other similarity metrics possible, e.g., cosine similarity

   - Limitations:

     > No history used in the recommendations.


   iii) (Weighted) Average of purchased items

   	A User liked product ABC & DEF, what other products recommend?

	1. Compute user-specific score for each item j in inventory by
	   combining similarities:

	   Score (user_u, new_item_j) = 1/2(S_j_abc + S_j_def)

	   note.- could also weight recent purchases more

	2. Sort Score(user_u, j) and find item j with highest similarity

	ooO(new product-j will be recommended to user_u based on  all the
	    scores in the matrix for all the  products that user_u just liked)

   - Limitations:

     > Does not utilize: context (e.g., timeofday), user features (e.g., age),
       product features (e.g., baby vs electronics)

     > Cold start problem: no info for new users.


d) Solution 3: Discovering hidden structure by matrix factorization ->
   	       Collaborative Filtering


# 1.4.2 Collaborative Filtering [2].55-59

  Problem: matrix of users-items with some pairs user-item unknown.
  Solution: all the users collaborate to fulfill the empty values.

  (i.e. Users scoring some movies based on some movies features) 


a) Problem formulation

   n_u: number of users
   n_m: number of movies
   r(i,j) = 1 iff user-j has rated movie-i

             | rating by user-j of movie-i    if r(i,j)==1
   y(i,j) = <    
             | ?			      otherwise


   Matrix: user/movies where X= features of the movies

   Approach: apply linear regression for every single user to predict y(i,j)
   

b) Algorithm [2].58

   i) Data pre-processing: mean normalization -> this resolves cold start
      problem for new users (but not for new movies)


   ii) step 1: initialize X^i; θ^j to small random values.

       ooO(this breaks symmetry, ensuring that the algorithm learns features
       	   that are different from each other)


   iii) step 2: minimize J(X, θ) using Gradient descent or other optimization
   	algorithm. Applying regularization!


   iv) step3: - For a user-j with parameters θ           |
                                                          > -> predict (θ'X)
              - For a movie-i with (learned) features X  |


c) (Optimization) "Low Rank Matrix" factorization model

  ooO(Low Rank Matrix is a linear algebra property)

  Y =  X * θ'

  where: 
  	 Y = Y(i,j) == 1 if movie-i is ranked by user-j

	 X = [X^i']

	 θ = [θ^j'] 


  FINALLY: What new movies to recommend to a user?

  - Given learned vector X, small || X^i - X^j || means movies are similar

  - Then recommend the n-smaller values


d) Conclusions: combining features and discovered topics [3.4].31

   • Features capture context: Time of day, what I just saw, user info, past
     purchases,…

   • Discovered topics from matrix factorization capture groups of users who
     behave similarly (e.g. Women from Seattle who teach and have a baby)

   • Combine to mitigate cold-start problem
     - Ratings for a new user from features only
     - As more information about user is discovered, matrix factorization
       topics become more relevant


# 1.4.3 Performance metric for recommender systems

  - Use precision & recall (GOTO 7.2): recommender systems only cares of the
    very few liked items -> skewed cases -> accuracy is a bad measure (GOTO
    warnings)


  a) Precision = True Pos. / (TP + FP)   # ( liked & recommended / recommended)

  b) Recall =    True Pos. / (TP + FN)   # ( liked & recommended / liked)


  Optimal recommender => precision = recall = 1
  
  


##------------------------------------------------------------------------------
# 1.5 Neural Networks [2].21-27 & [2].31
##------------------------------------------------------------------------------

NOTICE neural networks m.l. models: Supervised / Unsupervised/Reinforcement


HINT Neural networks -> Learning *very* non-linear features

     => A neural network learns its own features => complex & flexible features
     arise => ALOWING the CALCULATION of more COMPLEX NON-LINEAR functions.

     => a NN can represent non-linear separable functions (i.e. XOR)


# 1.5.1 NN Representation


       Input                      Hidden                    Output
       Layer                      Layers                    Layer


                               θ_1,0^1 = 1                  θ_1,0^2 = 1
              ((x_0 = a_0^1)) --------+           ((a_0^2)) -----+
                     |	              |                          |
                     v GOTO a_2^2     |                          |   
                                      |                          |
                                      |                          |
                    θ_1,1^1           v           θ_1,1^2        v
   ((x_1 = a_1^1)) ------------->  ((a_1^2))   ----------->  ((a_1^3))
         |                              ^                         ^
         |   θ_2,1^1                    |                         |
         |                              |                         |
	 +--------------------------+   |                         |
                                    |   |                         |
                                    |   |                         |
             θ_1,2^1                |   |                         |
         +------------------------------+                         |
	 |                          |                             |
	 |                          |                             |	 
         |            θ_1,2^        v               θ_1,2^2       |
   ((x_2 = a_2^1))  ------------>  ((a_2^2))  --------------------+



     a_1^2 = g(θ_1,0^1 * a_0^1  +  θ_1,1^1 * a_1^1  +  θ_1,2^1 * a_2^1)
     ...



a) Vectorized Notation

   a^j = g(z^j)

   z^j = θ^(j-1) * a^(j-1)


   Notes.-

   - a_k^j: k = node ; j = layer

   - g ≡ sigmoid function ooO(Derivable function to be used by G.D. Algorithm)


                                                             (+1 from bias)Ooo
                       | S_j units, layer-j     |                            o
   - Size of θ matrix <                          => size θ^j = S_j+1 * (S_j + 1)
                       | S_j+1 units, layer-j+1 |
 

b) Examples and intuitions [2].22

   - AND, OR: no hidden layers
   
   - XOR, XNOR: requires a hidden layer


c) Multiclass classification

                                  | h, y ∉ {1, 2, .., n}
   X -> a^j -> ... -> [h]  t.q.  <
                                  | h, y ∈ [1 0 .. 0]' , [0, 1, .. 0]', [0..1]'


# 1.5.2 NN Learning

a) Representation

   L:        number of layers
   S_l:      number of units in layer-l (not counting the bias)
   K:        number of units/classes in the output layer
   h_θ(x)_k: hypothesis in the k-th output   

b) Cost Function  ooO(generalization of Logistic Regression with Regularization)

   J(θ) = -1/m ((SUM_i=1_to_m SUM_k=1_to_K y_k^i log((h(x^i)_k)) +
   	        + (1-y_k^i) log (1-(h(x^i))_k) ) +
		# regularization part
	        λ/(2m) SUM_l=1_to_L-1 SUM_i=1_to_Sl SUM_j=1_to_S_j+1 (θ_j,i^l)^2

c) Backpropagation Algorithm (GOTO 2.2)


# 1.5.3 NN as a machine learning predictor  [2].27

a) Architecture selection

   - Input units = #features = size(x^i)

   - Output units = #classes = size(y^i)
   
   - How many hidden layers ?
     Does not exists any rule -> use NN cross validation (GOTO 6.4)

     Note.- Theorem of Finahashi: NN with one only hidden layer can compute,
     	    (with a little error), any function iff the hidden layer has #units
     	    enough.

- How many units per hidden layer ?
     > All the hidden layers MUST have the same number of units.
     > BUT does not exists any rule to decide how many units must have a layer.

   
b) TRAINING the NN (6 steps)

   step 1) Randomly initiate weights.

   step 2) Implement forward propagation to calculate h_θ(x^i)

   step 3) Implement the cost function (J(θ))

   step 4) Implement backpropagation to compute the Gradient (D^l)

       ooO(
	   
   	   FOR i=1 to m   ooO(pairs (x^i, y^i))

	       Forward-propagation on (x^i, y^i)
	       Back-propagation on (x^i, y^i)
	       
                           | activations a^l
	       ... to get <                     ; l= 2, 3, .., L
                           | delta items δ^l

   	   EN_FOR

	   Finally compute D^l

	   )


   step 5) Use Gradient Descent ONCE to confirm that Back-propagation works OK
   	   and then disable Gradient Descent.

   step 6) minimize J(θ) using G. D. alg. OR an advanced optimization method


	   
##------------------------------------------------------------------------------
# 1.6 Deep Learning
##------------------------------------------------------------------------------

Def Is a branch of machine learning based on a set of algorithms that attempt
    to model high-level abstractions in data by using MULTIPLE processing
    LAYERS with complex structures or otherwise, composed of MULTIPLE
    NON-LINEAR TRANSFORMATIONS. [5.1]

    Keys: (1) MULTIPLE LAYERS of nonlinear processing units
    	  (2) the supervised or unsupervised learning of feature
     	  representations in each layer, with the layers forming a hierarchy
     	  from low-level to high-level features.

Applications: [5.1]
    - Automatic speech recognition
    - Image recognition
    - Natural language processing
    - Drug discovery and toxicology
    - Customer relationship management


# 1.6.1 Neural Network model to solve deep learning

- NN (GOTO 1.5)


# 1.6.2 Application of deep learning to computer vision

a) Image features

- Features = collections of locally interesting points (angles, ... => eye,
  nose, ...), combined to build classifiers => make predictions (face, no face)


b)  Standard image classification approach

    Input -> extract features (hand-created) -> Use simple classifier
                                                (e.g. logistic regression, SVMs)

    - PROBLEM Hand-created features are very painful to design.

    - SOLUTION deep-learning NN implicitly learns features:

      Input -> layer 1 -> .. -> layer n -> Prediction
    

# 1.6.3 Challenges of deep learning

Pros

• Enables learning of features rather than hand tuning

• Impressive performance gains
  - Computer vision
  - Speech recognition
  - Some text analysis

• Potential for more impact


Cons

• Requires a lot of data for high accuracy

• Computationally really expensive

• Extremely hard to tune
  - Choice of architecture
  - Parameter types
  - Hyperparameters
  - Learning algorithm


    Computational cost+ so many choices = incredibly hard to tune


# 1.6.4 Deep Features: deep learning + transfer learning [e3] [e4]

Hint  Deep features allow to build neural networks EVEN WHEN YOU DON'T HAVE A
      LOT OF DATA.


- Transfer learning: Use data from one task to help learn on another task.


a) Transfer Learning workflow

                                           | T.set => Learn simple classifier
   SOME labeled  ->  Extract features  -> <                       |
        data         with a NN trained     |                      v
	            on a different task    | Validation set => validate
                          (*)

    (*) Problem: current data set too short to extract good features    
    	Solution: use instead the (valid) features extracted in ANOTHER (long
    		  enough) domain trained for a similar problem.


b) Intuition:

   - LOTS of data => Learn NN => Great accuracy CONCRETE case (i.e. cat vs dog)

   - SOME data    => NN as feature extractor => Great a. on SEVERAL categories
                     + simple classifier


c) Transfer Learning detail

   - NN layers =    generic layers   +  problem-specific layers
                 (i.e. eye detector)       (i.e. cat vs dog)


   - T.L. application =

     1) use generic layers as feature extractors (keeping weights fixed)

     2) Ignore (cut) the very specific layers

     3) Apply a simple classifier after the last generic layer



##==============================================================================
## 2.- Supervised Learning Algorithms
##==============================================================================


   Supervised Learning work-flow


  +---------------+   +--------------------+  X  +----------+  h
  | Training data |-->| Feature extraction |---->| ML model |-------->
  +---------------+   +--------------------+     +----------+    |
         |                                            ^          |
         | y                                          |          |
         |                                                       |
         |                                            θ          |
         |                                                       |
         |                                            ^          |
         |                                            |          |
         |                                    +--------------+   |
         |      		              | ML algorithm |   |
         |                                    +--------------+   |
         |                                            ^          |
         |                                            |          |
         |                                            |          |
         |                                  +----------------+   |
         +--------------------------------->| Quality Metric |<--+
                                            +----------------+   



##------------------------------------------------------------------------------
# 2.1 Gradient Descent Algorithm
##------------------------------------------------------------------------------

  NOTICE always using Batch G.D. (See Glossary)

- Resolution for:
  
  > Multiple Linear Regression [2].p5-6
  > Simple Linear Regression (multiple l. reg. where n=1) [2].ML.C3
  > Logistic Regression


  # 2.1.1 Equation

  # Notation note.- theta = θ
  # Notation note.- h_theta = h

  REPEAT
  {
    grad = (1/m) * ( SUM_i=1_to_m ( h( x^i ) - y^i ) * x_j^i )
    θ_j = θ_j - (α * grad)

    # i = 1 .. m: training example
    # j = 0 .. n: feature
    # x_0^i = 1 ∀ i
    # Batch GD: updating θ_j simultaneously# j = 0..n
    
  }


  # 2.1.2 Vectorized Notation (see glossary for details)

  	# INFO Notation in vectorized notation, uppercase means MATRIX &
  	# lowercase means scalar variable.
	# Exception: y is the solution vector (vector == n x 1 matrix )

  a) Linear Regression
  
     > h_theta(x) = X * θ


     > J(θ) =  (1/2m) (Xθ-y)' (Xθ-y)

       #INFO (Xθ-y)' * (Xθ-y) is just the error calculation, thus (h-y)**2,
       #     in matrix notation (scalar product).


     > grad = (1/m) * X' * (Xθ-y)
       θ = θ - (α * grad)


  b) Logistic Regression
  
     > h_θ(x) = g(Xθ)


     > J(θ) = 1/m ( log(g(Xθ))'y + log(1-g(Xθ))'(1-y) )


     > grad = (1/m) * X' * (g(Xθ)-y)  # logistic vs linear:  g(Xθ) vs Xθ
       θ = θ - (α * grad)


  # 2.1.3 Speeding up Gradient Descent

  	 - feature scaling technique (GOTO 4.1)
	 - mean normalization technique (GOTO 4.2)
	 - Polynomial Regression technique (GOTO 4.3)


  # 2.1.4 Debugging Gradient Descent [2].p7
  
  a) α selection for GD

    > Goal is to get the convergence curve as expected (3.c.1)

    > Proven: if α is small enough then J will decrease on every iteration
    > NG suggestion: decreasing α by multiples of 3:
      0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, ...

  b) Numbers of iterations: it is hard to predict ∀ problem.

  c) Correct Convergence Detection

    > Automatic convergence test (the correct in theory)

   	IF J(theta) <= Epsilon in one iteration THEN declare convergence

    > Plot of convergence (the easiest in practice)

   	(plot axis: θX = #iterations ; θY = J)
	Convergence iff curve form is the expected (fast fall - medium fall -
	almost flat)




##------------------------------------------------------------------------------
# 2.2 Backpropagation Algorithm
##------------------------------------------------------------------------------

Def [5.3] Backpropagation, an abbreviation for "backward propagation of
    errors", is a common method of training artificial neural networks USED IN
    CONJUNCTION WITH AN OPTIMIZATION METHOD such as gradient descent.


1.- GOAL: The method calculates the gradient of a loss function with respect to
    	  all the weights in the network (θ_j,i^l)

2.- USE The gradient is fed to the optimization method which in turn uses it to
    	update the weights, in an attempt to minimize the loss function.

	-> to predict the result of a new input.


WARNING Backpropagation requires a known, desired output for each input value
	in order to calculate the loss function gradient. It is therefore
	usually considered to be a supervised learning method (although it is
	also used in some unsupervised networks such as autoencoders)


Detail [2].23-27


##------------------------------------------------------------------------------
# 2.2. Normal Equation Method [2].p8
##------------------------------------------------------------------------------

- Mathematical (not AI) method to solve linear regression: finding the OPTIMAL
  theta values without iterations.


  θ = inv(X' * X) * X' * y   #WARNING computation order is θ(n**3)

  #INFO Octave notation: θ = pinv(X) * y 


- GD vs Normal Equation


          GD                vs        Normal Eq.
 ---------------------------|---------------------------
                            |
      Needs α           |          No α
                            |
  Needs many iterations     |        No iterations
                            |
         O(n)               |          O(n**3)           # WARNING key fact
 ---------------------------|---------------------------
 
           ||                             ||
           vv    ((according to Ng))      vv
	   
 ---------------------------|---------------------------	   
 OK for large n (n>=10**4)  |  OK for short n (n<10**4)  # CONCLUSION !!



##==============================================================================
## 3.- Unsupervised Learning Algorithms
##==============================================================================


   Unupervised Learning work-flow


  +---------------+   +--------------------+  X  +----------+  h
  | Training data |-->| Feature extraction |---->| ML model |-------->
  +---------------+   +--------------------+     +----------+    |
                                                    ^            |
                                                    |            |
                                                                 |
                                                    θ            |
                                                                 |
                                                    ^            |
                                                    |            |
                                              +--------------+   |
      		                              | ML algorithm |   |
                                              +--------------+   |
                                                    ^            |
                                                    |            |
                                                    |            |
                                            +----------------+   |
      		                            | Quality Metric |<--+
                                            +----------------+   



##------------------------------------------------------------------------------
# 3.1 k-means algorithm  [2].41-42
##------------------------------------------------------------------------------

a) Algorithm notes

   - μ_k: k-th centroid ; 1 ≤ k ≤ K

   - x^i: i-th example ; 1 ≤ i ≤ m

   - 'closest' ≡ norm(x-μ)^2 ≡    min  || x^i - μ_k ||^2   ~(Voronoi diagram)
                                 k=c^i

   - Convergence reached => after several iterations the clusters not affected
				

b) Steps

STEP_1	!Randomly! initiate K cluster centroids μ_1, μ_K ∈ R

STEP_2	REPEAT until Convergence{

  STEP_2_a "cluster assignment step": find closest centroid to each input var.

	  FOR i=1 TO m   // of the x-examples
	     c^i:= index (from 1 to k) of cluster centroids closest to x^i
	  END_FOR


  STEP_2_b "move centroids step"

	  FOR k=1 TO K   // of the K centroids 
	      IF k has zero points assigned
	      	 THEN remove k of random re-initiate it.
	      ELSE
		μ_k := average (mean) of the points assigned to cluster k
	      END_IF
	  END_FOR

	} # end_repeat


# 3.1.1 k-means for non-separated clusters

  a) Separated clusters: normal mode

  b) Non-separated clusters: i.e. t-shirts sizes: small, medium, large -> the
  clusters are contiguous.


# 3.1.2 Optimization objective


a) Cost function = J(c^1, c^m, μ_1, μ_k) = 1/m SUM_i=1_to_m || x^i - μ_c^i ||^2

 - Meaning: x^i has the c-kernel assigned

 - e.g.
   X set = {x_1, x_2, x_3} ; centroids = {μ_1, μ_2, μ_3}
   {x_1 -> μ_2 ; x_2 -> μ_2 ; x_3 -> μ_1
   then J = 1/3 ((x_1-μ_2)^2 + (x_2-μ_2)^2 + (x_3-μ_1)^2)


                                   | cluster assignment step: min J(x^1,.., x^m)
                                   |                          (μ fixed)
   min J(c, μ) = exec. k-mean alg.< 
   c,μ                             | 
                                   | move centroids step: min J(μ_1,.., μ_k)


HINT k-means ALWAYS converge (global or local minimum) [2].42

     - Using k-means J never can increase, although IT CAN FALL TO A LOCAL
       MINIMUM => apply random init. to reduce the probability of local min.


# 3.1.3 Random initialization of the centroids [e1]

  i)   Having k<m centroids
  ii)  RANDOMLY pick k training examples
  iii) Set μ_1, μ_2, μ_3 equal to theses examples

PROBLEM   How to avoid some (high) percentage of local minimum ?

SOLUTION i) run ONE ITERATION of the algorithm on many (50 to 100) random
	    initializations ...
	 ii) ... and then pick the one with min J(c, μ)


# 3.1.4 Choosing the number of clusters

HINT Too many clusters will over-fit the data (i.e. k==m)

* Usually k is selected by hand.

* automatic modes: "THE ELBOW METHOD"
  Fact: as k increase, J will always decrease
  - Ideal elbow evolution: linear fall + ~horiz fall => elbow point = k value
  - Actual elbow evolution: log. => no clear elbow
  
HINT Empirically tested that k must be ∈ [2-10]  [2].42


##==============================================================================
## 4.- Auxiliar techniques
##==============================================================================

# 4.1 Feature scaling [2].p6

    Xi = Xi / S    ; S = range(X)

    Used to speed up Gradient Descent Alg.


WARNING Feature scaling when S is close to 0
	(S ~= 0) iff vector feature ~= constant => bad feature => the feature
	must be removed => PROBLEM: S does not exists anymore.

  
# 4.2 Mean Normalization [2].p6

   Xi =  Xi / u   ; u =  mean(X)

   Used to speed up Gradient Descent Alg.


# 4.3 Polynomial Regression [2].p8

   h(x) = θ0 + θ1(x1) ...  ==>  h(x) = θ0 + θ1(x1) +  θ2 * sqrt(x1)

   	where (θ2 * sqrt(x1) ) is created to change the behaviour of the curve
   	to get a bettet fit of the solution (y)

   Used to improve the hypothesis function (h)

   INFO    d: polynomial degree of h(x)


# 4.4 Advanced Optimization [2].14, [3]video6.6_time=5:45

  - Using already known (libraries) learning algorithms: GD, L-BFG [4.3], BFGS
    [4.4], Conjugate gradient method [4.5], instead of programming one.

  WARNING Used in [3] with Octave code
  WARNING Used in [4] within the GraphLab tool.

  a) Input required for the algorithms: depends on the library / tool
     (i.e. Octave: code for 'grad', and code for J(θ))

  b) Plus 
     - Not needed to understand how they work, just use it (Octave libs).
     - α is calculated automatically.
     - Faster than manual algorithms.

  c) Minus
     - Complex than  manual algorithms.
     


##==============================================================================
# 5.- Regularization (solving the over-fitting problem)
##==============================================================================

# 5.1 Overfitting Problem (high variance - related to precision) [2].p17

  - Detection: h(x) match the training set almost perfectly.

  - Consequences: h(x) bad generalization.
  
  - Causes & solutions:

    i) Cause: too many features (n >> m). This means that some features are not
       representative to find the solution.

       Solution (-n): reduction of the number of features; manually or
       automatically (Model Selection algorithm)
       
       Solution (+m): add more training examples.
       
    ii) Cause: all the features are useful to find the solution, but the cost
    	function (J) is too much complex.

	Solution: Regularization


    WARNING First Mandatory action to get a solution: split the data set into:

    	    - training set (get Theta values)

	    - cross validation set (get λ, α, d, ...)

	    - test set (check the goodness of the algorithm)


# 5.2 Underfitting Problem (high bias - related to exactitude) [2].p17

  - Detection: h(x) does not fit the training set.

  - Consequences: h(x) bad generalization.
  
  - Causes & solutions:

    i) Cause: very few features (n << m). 

       Solution (+ n): add features.
       
    ii) Cause: cost function (J) is too much simple (i.e. h(x) = cte = 2)

    	Solution (+ d): increase the complexity of J (i.e. Polynomial Regression
    	technique)


# 5.3 Regularization [2].p17-20

  WHY Solution to overfitting problem caused by an excesive complex cost
      function, and when all the features are usefull to find the solution.

  HOW keep all the features but reduce the weight of some/every feature by
      incresing their cost.

  i) Decrease λ -> to fix0' high bias problem
  
  ii) Increase λ -> to fix high variance problem

  

##==============================================================================
# 6.- Advice for applying Machine Learning [2].page29-32
##==============================================================================

#INFO Notation: 'd' is the polynomial degree of h(x)


# 6.1 Is h(x) OK? - Evaluating the hypothesis function

  Overfitting => split the data in different sets: training, cv, test

  a) Error sets:
     - Training Error: X_train, y_train, m_train)
     - Cross validation Error: X_cv, y_cv, m_cv)
     - Test Error: X_test, y_test, m_test)

  b) Test Steps:
  
     i) Learn θ

     ii) Get J_train & J_vc (WITHOUT REGULARIZATION) to paint the learning
     	 curves to detect bias/variance errors.

     iii) Compute test set error (X_test, y_test, m_test), WITHOUT
     	  REGULARIZATION.

     	  Linear Error:   error(h,y) = 1/2m ∑((h-y)**2)

	  Logistic Error: error(h,y) = 1/2m ∑((h-y)**2)
	  	   	    OR
	  	   	  error(h,y) = miss-classification error (GOTO 1.2.4)

     iv) Compute the "Average Test Error" = 1/m ∑err(h,y)
     	     (X_test, y_test, m_test)


# 6.2 Are the data sets OK? - Model selection & train/cv/test sets

  We need to split the data set into three different sets:

  - training set (60%): used to optimize h (get Theta values)
  
  - cross validation set (20%): used to optimize other training parameters
    (λ, α, d, ...)

  - test set (20%): used to check the goodness of the solution
  

  WHY? Because J_training has been optimized for the training set -> J_training
       bad generalization.

       And because J_cv has been optimized for (e.g.) 'd' -> J_cv bad
       generalization.

       But the test set has not been used yet -> J_test good means that h(x)
       will have good generalization


  Goal: selection of the best polynomial degree for h(x)

  Steps:

  i)   Training set: ∀ 'd', min J_train = 1/2m SUM((h-y)**2)

  ii)  Cross Validation set:  ∀ 'd', min J_cv

  iii) Pick 'd' where J_cv is minimum

  iv)  Estimate generalization error for the test set: J_test(O^d_min)


# 6.3 Bias/Variance

  INFO High variance => over-fitting problem
  INFO High bias => under-fitting problem


# 6.3.1 Trade-off intuition 

  i) Complex Model (high polynomial degree) ->
     -> very sensitive to data ->
     -> highly affected by changes in X (input)

     => high variance & low bias

  i) Simple Model -> rigid -> lowly affected by changes in X (input)

     => low variance & high bias


HINT Models with less bias need more data to learn (initially slow learning ->
     curve slope linear instead of logarithmic), but do better with sufficient
     data (train-cv gap smaller)



# 6.3.2 Is 'd' OK? - Learning curves: 'd' selection

  - Plot (OX is 'd'; OY is J(theta))

    INFO J result high: means J value is distant to 0 

    INFO J result low: means J value is close to 0

  - Check the plot values of J_train & J_cv to check/find 'd'

  For any point in the plot, this is the meaning:
  
  case High bias: if (J_train ~= J_cv) and (both of them are high)

  case High variance: if (J_cv >> J_train ) and (J_train low)

  case optimal value for 'd': the lowest point for both J_train & J_cv where
       	       	     	      (J_train ~= J_cv)


# 6.3.3 Is 'm' OK? - Learning curves: 'm' selection

  - Plot (OX is 'm'; OY is J(theta))

  - Check the plot values of J_train & J_cv to check/find 'm'.

  For any point in the plot, this is the meaning:
  
  case High bias: if (J_train ~= J_cv) and (both of them are high)

  case High variance: if (J_cv >> J_train ) and (J_train low)


# 6.3.4 Is λ OK? - Regularization & Bias/Variance: selecting λ


# 6.3.5 The decision process

  a) Fixing high variance problem (over-fitting)

     ... by simplifying the model

     i)   (+l) Increase λ (in regularization).

     ii)  (-n) Remove some (non representatives) features.

     ... by adding training examples

     iii) (+m) Add training examples.


  b) Fixing high bias problem (under-fitting)
  
     ... by increasing the complexity of the model

     i)   (-l) Decrease λ (in regularization).

     ii)  (+n) Add features.

     iii) (+d) Add polynomial features.


     WARNING Adding training examples (+m) does not fix high bias.
     

# 6.4 Neural Networks Diagnosis [2].31

  a) Number of parameters ?

                                    | - under-fitting
     - NN with few parameters  =>  <
                                    | - computationally cheaper


                                    | - over-fitting => use (λ) regularization
     - larger NN               =>  <
                                    | - computationally expensive


  b) Number of hidden layers ?

     => Use NN cross validation (J_cv)

     i) start with one hidden layer & calculate J_cv

     ii) try with different number of hidden layers & calculate J_cv for each

     iii) Select the value with minimum J_cv
     


##==============================================================================
# 7.- Machine Learning systems design [2].page33
##==============================================================================

# 7.1 Error analysis:

- Recommended approach to solve a ML problem

  a) Start with a quick and dirty algorithm.
     > Test this alg. on the cross validation (cv) data set

  b) Plot learning curves to decide:
     > more data (+m) ?
     > more features (+n) ?
     > ...

  c) Error analysis: MANUALLY examine the errors on the cross validation (cv)
     data set to find systematic trends.

- Numerical evaluation: set a measure of your algorithm (%error, accuracy,
  ...), to see the results quickly.


# 7.2 Error metrics for skewed classes: apply Precision-Recall trade-off [4.1]

    - (Type of) Error Matrix

                                      True  class
		
                   |          1             |          0              |
                ---|--------------------------------------------------| 
                   |                        |                         |
    Predicted   1  |      True Positive     |   (FP) False Positive   |
                   |                        |                         |
                ---|--------------------------------------------------|
     class         |                        |                         |
                0  |   (FN) False Negative  |      True Negative      |
                   |                        |                         |
                ---|--------------------------------------------------|



    a) Precision =  True Positive / (TP + FP)    # ( TP / ∑ predicted 1s)

    b) Recall =     True Positive / (TP + FN)    # ( TP / ∑ true 1s)

    c) error =      #mistakes / #total values	 # the best possible is 0
    
    d) Accuracy =   ∑ true / ∑ total = (TP + TN) / (TP + TN + FP + FN)
       		=   #correct / #total values = 1-error	# best possible is 1

    e) Numerical evaluation: f1score = (2 * P * R) / (P + R)


HINT    Train P & R on the cv_set
                                          | inc threshold => inc P  &  dec R 
                                          |
HINT	Predict 1  if h(x) >= threshold  <
                                          | 
					  | dec theshold  => dec P  &  inc R


WARNING If we want to assure recall (i.e. to detect the max. number of skewed),
	then the precision tends to fall.

WARNING Accuracy is a bad index to evaluate skewed classes (always high)


HINT what accuracy does my application need?
     - What is good enough for my user’s experience?
     - What is the impact of the mistakes we make?


# 7.3 How much data should we train?

    a) Choose the correct features (X set) to have enough information:

       Given X, would a human expert predict y?

    b) First: get a low bias algorithm.
       Second: reduce overfiting and increase the accuracy of the training set.



##==============================================================================
# 8.- Some Machine Learning Problems 
##==============================================================================


##------------------------------------------------------------------------------
# 8.1 Document Retrieval: similarity & clustering
##------------------------------------------------------------------------------

Note.- corpus: large set of documents (i.e. library)


Issue_1 How to determine that two documents are similar? -> similarity 

Issue_2 How to retrieve similar documents -> clustering


# 8.1.1 How to measure similarity? - Bag of words model

  - Ignore order of words
  
  - Count # of instances of each word in vocabulary


 a) Problem representation

    + vector of words:
      - index i: i-th word of the document
      - v[i]: Count # of instances of each word

    + Measure similarity of 2 documents = similarity of the two vectors of
      words  v, w = ∑(v[i] * w[j])

      (e.g) v [1|0|0|5|3|0|0|1|0]
            w [3|0|0|2|0|0|1|0|0]   = 1*3 + 5*2 = 13


 b) Issues with words counts - Doc Length

      (i.e.) doc1 & doc2 with 2 pages / similarity = 1*3 + 5*2 = 13
      	     doc3=doc1 twice & doc4=doc2 twice:
	     	 -> expected similarity = 13 * 2 = 26
		 -> obtained similarity = 2*6 + 10*4 = 52

     SOLUTION = normalize => norm(vector) = vector / norm(vector)

      (e.g) v [1|0|0|5|3|0|0|1|0]  => v_norm [1/6|0|0|5/6|3/6|0|0|1/6|0]
            w [3|0|0|2|0|0|1|0|1]  => w_norm [3/√15|0|0|2/√15|0|0|1/√15|0|1/√15]

	    norm(v) = √(1^2 + 5^2 + 3^2 + 1^2) = 6
	    norm(w) = √(3^2 + 2^2 + 1^2 + 1^2) = √15

	    similarity (v_norm, w_norm) = 1/6*3/√15 + 5/6*2/√15 = 0.559


 c) Issues with words counts - rare words

    Note.- Rare globally: appears rarely in corpus

    Note.- Common locally:  appears frequently in document.

    - Rare word: rarely globally

    - Important word: common locally but rare globally.

    - We need to increase the importance of the rare words  to avoid loosing
      them.
   

   c.1) tf_idf: Term frequency – inverse document frequency

   	- (Measure) Trade off between local frequency and global rarity.

	- Common terms tend to disappear (tf-idf = 0)

   	- Important words tend to have a high tf-idf

	  => Words with highest TF-IDF are much more informative.


    (Equation)
    
    w: word
    d: doc
    D: corpus
    N: total number of documents in the corpus N = {|D|}
    |{d ∈ D: t ∈ d}|: number of documents where the term w appears

    • tf(w, d) = number of times word 'w' appeared in document 'd'
	 
    • idf(w, D) = log (N / (1 + |{d ∈ D: t ∈ d}|))
      #WARNING (1 + ...) to avoid division by zero if w ∉ D
      #INFO idf(Common words) tend to 0 because (log -> log 1 -> 0)

    • tf-idf(w, d, D) = tf(w.d) * idf(w,D)


   (e.g)
   Term frequency vector      tf = [ | |1000| | | |5 | | ]
   Inv doc frequency vector  idf = [ | | 0  | | | |4 | | ]
         tf-idf(w,d) = ∏(tf*idf) = [ | | 0  | | | |20| | ]



# 8.1.2 Retrieving similar documents

 a) Algorithm - Nearest neighbor search

    Problem representation

    + Input: Query article (a document)
    + Corpus: set of docs.
    + Specify: distance metric
    + Output: (list of k) most similar articles

    k - Nearest neighbor (k=1)

      	FOR each article 'a' in corpus
	    Compute s = similarity(query, a)
	    IF (s > best_s) THEN
	       add a to output
	       best_s = s
	    END_IF
	END_FOR

	return output


 b)  Algorithm - Clustering

    case 1: some classes are known ->  (supervised learning ) multiclass
    	    classification problem.

    case 2: unlabeled classes -> (unsupervised learning ) k-means algorithm.



##==============================================================================
## Hints
##==============================================================================


# convergence

HINT (Batch) Gradient Descent algorithm ALWAYS converge to GLOBAL minimum for
     linear regression problems. [2].ML.C3


HINT Logistic Regression Cost Function (sigma) is convex => Gradient Descent
     algorithm ALWAYS converge to GLOBAL minimum


HINT k-means ALWAYS converge, BUT not always to a global minimum. [2].42


# others

HINT (Batch) Gradient Descent algorithm scales better than the numerical method
     (Normal Equations Method), for large training sets (n>10000)


HINT Logistic Regression: class probabilities are extremely useful in a practice


HINT Why train/cv/test sets: (GOTO 6.2)


HINT Models with less bias need more data to learn (initially slow learning ->
     curve slope linear instead of logarithmic), but do better with sufficient
     data (train-cv gap smaller)


HINT  Decicion boundary is a property of 'h_θ(x)',  it is not a property of 'X'

HINT Neural networks -> Learning *very* non-linear features



##==============================================================================
## Warnings
##==============================================================================


WARNING Accuracy is a bad index to evaluate skewed classes (always high)


WARNING Feature scaling when S is close to 0
	(S ~= 0) iff vector feature ~= constant => bad feature => the feature
	must be removed => PROBLEM: S does not exists anymore.


WARNING Multiple Regression vs Multivariate Regression
	Multiple Regression:      y = f(X1, .., Xn)
	Multivariate Regression:  f(Y1, .., Yn) = f(X1, .., Xn)


WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ



##==============================================================================
## Annex.- Maths Review
##==============================================================================



##==============================================================================
## Annex.- Linear Algebra Review
##==============================================================================



##==============================================================================
## Annex.- Glossary 
##==============================================================================

A


B

- Batch Gradient Descent algorithm: for every iteration step of the GD
  algorithm, we SIMULTANEOUSLY use (update) the entire training set.


C

- Classification Problem: to predict the actual DISCRETE valued output
  (i.e. {yes, no})
  
- Clustering (Cluster analysis): cluster analysis or clustering is the task of
  grouping a set of objects in such a way that objects in the same group
  (called a cluster) are more similar (in some sense or another) to each other
  than to those in other groups (clusters). Cluster analysis itself is not one
  specific algorithm, but the general task to be solved. [4.8]


- Cost function: function to get the learning algorithm result.
  i.e. in linear regression this is the function to minimize

- cv: cross validation set


G

- Gaussian Distribution (Normal Distribution) [2].page.ML_C5

  x ~ N(μ,σ2)

  o: desviación típica
  o**2: varianza


L

- Labeled data: data for which we know its value, thus, given a X data set, it
  is labeled iff we also know Y.
  Used to evaluate the system: cv_set and test_set.


N

- Non invertibility Problem [2].p9: Matrix non invertible -> can not be used to
  GD calculation.
  Cause -> Solution: feature redundancy -> remove the dependent feature
  Cause -> Solution: (n >= m) -> remove some features or regularization.
  INFO In Octave, pinv(X) ALWAYS calculates the inverse matrix of X.

- Normal Equation Method: mathematical (not AI) method to solve linear
  regression. This method is suggested for low size training sets.


O

- Ordinary Least Squares (OLS): method for estimating the unknown parameters in
  a (linear) regression problem


P

- Precision: see 4.4


R

- Recall: see 4.4

- Regression Problem: predict the actual CONTINUOUS valued output.

- RMSE: Root-mean-square error (or r-m-s deviation) -
  https://en.wikipedia.org/wiki/Root-mean-square_deviation


S

- Sentiment analysis (also known as opinion mining) refers to the use of
  natural language processing, text analysis and computational linguistics to
  identify and extract subjective information in source materials. (wiki)
  Logistic Regression is used to solve sentiment analysis.

- Sigmoid Function: "g(z) = 1 / (1 +  e**(-z))"   [2].ML.C5, [4.2]
  Cost function used to solve logistic (classification) regression problems.
  WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ


- Skewed classes: classes that are very rare in the data set.
  (e.g) rain vs not rain -> 50% / 50% -> no skewed
  	cancer vs not cancer -> 0.05% / 99.5% -> cancer is a skewed class
  Skewed classes can be evaluated using the Precision/Recall technique (see 4.4)
  WARNING Accuracy is a bad index to evaluate skewed classes (always high)

- Supervised Learning (Algorithms): for every example of the data set, we are
  provided with the "correct answer" to predict. Thus, the training example
  sets are provided to the algorithm.


U

- Unsupervised Learning (Algorithms): neither the training set, nor the possible
  solution are provided to the algorithm. The algorithm itself make its own
  conclusions as a result to an input; and later the human engineer will study
  this conclusions.


V

- Vectorized Notation (or Matrix Notation): used to optimize the speed of the
  calculations.
  Relies on the mathematical software libraries used: using the library's
  matrix operations instead of manual programming using "for loops".
  The speed up can be in order of hundreds (empirically tested)


##==============================================================================
## References
##==============================================================================

[1] Machine Learning course - U. Stanford (Andrew Ng)

[2] Notest at the ML (paper) notebook.

[3] Machine Learning course - U.Washington
[3.1] regression problems - 1.regression-intro-annotated.pdf 
[3.2] classification problems - 2.classification-annotated.pdf
[3.3] clustering problems - 3.clustering-intro-annotated.pdf
[3.4] recommender systems - 4.recommenders-intro-annotated.pdf

[4] Wikipedia
[4.1] Precision/Recall - https://en.wikipedia.org/wiki/Precision_and_recall
[4.2] Sigmoid function - https://en.wikipedia.org/wiki/Sigmoid_function
[4.3] L-BFGS algorithm - https://es.wikipedia.org/wiki/L-BFGS
[4.4] BFGS algorithm - https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm
[4.5] Conjugate gradient method - https://en.wikipedia.org/wiki/Conjugate_gradient_method
[4.6] Linear classifier - https://en.wikipedia.org/wiki/Linear_classifier
[4.7] Decision boundary - https://en.wikipedia.org/wiki/Decision_boundary
[4.8] Clustering - https://en.wikipedia.org/wiki/Cluster_analysis


[5] Deep Learning
[5.1] deep learning wiki - https://en.wikipedia.org/wiki/Deep_learning
[5.2] http://deeplearning.net/
[5.3] Backpropagation algorithm - https://en.wikipedia.org/wiki/Backpropagation



##==============================================================================
## Code examples
##==============================================================================

[e1] k-means random initialization - /curso_stanford/programming_exercices/ex7.week8/mlclass-ex7/kMeansInitCentroids.m

[e2] recommender_system - /curso_uw/programming_exercices/4.recommending_songs/song_recommender.ipynb

[e3] Deep_Features_for_Image_Classification - /curso_uw/programming_exercices/5.deep_features_for_image_retrieval/Deep_Features_for_Image_Classification.ipynb

[e4] Building an image retrieval system with deep features¶ - /curso_uw/programming_exercices/5.deep_features_for_image_retrieval/Deep_Features_for_Image_Retrieval.ipynb



#######################################
# http://www.rapidtables.com/math/symbols/Basic_Math_Symbols.htm
#######################################
# ∀
# ∏
# ∑
#######################################
# ∃
# ∈
# ∉
# ∩
# ∧
# ε
# ∇
#######################################
# α
# β
# λ
# θ theta
# δ delta
# π
# σ sigma
# ∇ gradient
# N(μ,σ2)
# μ mu
#######################################
# ∝
# ∞
# √
# ≈
# ≤
# ≥
# ±
# ⊂
# ≡
# ±
# ∓
#######################################
# •
#######################################
