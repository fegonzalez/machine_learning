

##==============================================================================
## INDEX
##==============================================================================

# 1.- Machine Learning methods to solve problems
#
#     1.1 Linear Regression
#     	  1.1.1 Linear Regression basics
# 	  1.1.2 Problem description
#     1.2 Logistic Regression
#     	  1.2.1 Logistic Regression basics
# 	  1.2.2 Linear Classifiers
# 	  1.2.3 Decision Boundary: What (classes) can h(x) represent?
# 	  1.2.4 Estimated (class) probabilities: how confident is a prediction?
# 	  1.2.5 Classification Problem description
#     	  1.2.6 Multiclass Classification: one-vs-all algorithm (method)
# 	  1.2.7 Miss-classification error
#
#     1.3 Clustering [2].41-42
#
#     1.4 Recommender Systems
#
#     1.? Dimensionality Reduction [2].43-46
#
#     1.? Anomaly Detection  [2].47-53
#
#     1.? Neural Networks [2].21-27 & [2].31  NOTICE Super/Unsup/Reinforc model
#
#     1.? Support Vector Machines [2].35-38   NOTICE  Supervised learning model
#
#     1.? Large Scale Machine Learning [2].61-64


# 2.- Supervised Learning Algorithms
#
#     2.1 Gradient Descent Algorithm
#     	   2.1.1 Equation
#     	   2.1.2 Vectorized Notation
#     	   2.1.3 Speeding up Gradient Descent
#     	   2.1.4 Debugging Gradient Descent [2].p7

# 3.- Unsupervised Learning Algorithms
#
#     3.1 k-means algorithm
#     	  3.1.1 k-means for non-separated clusters
# 	  3.1.2 Optimization objective
# 	  3.1.3 Random initialization of the centroids [e1]
# 	  3.1.4 Choosing the number of clusters


# 4.- Auxiliar techniques
#
#     4.1 Feature scaling  
#     4.2 Mean Normalization
#     4.3 Polynomial Regression
#     4.4 Advanced Optimization


# 5.- Regularization (solving the over-fitting problem)
#
#     5.1 Overfitting Problem (high variance)
#     5.2 Underfitting Problem (high bias)
#     5.3 Regularization
#     5.4 Regularized Linear Regression
#     	   5.4.4.1 Vectorized Linear Regression with Regularization
#     5.5 Regularized Normal Equation
#     5.6 Regularized Logistic Regression
#     	   5.4.6.1 Vectorized Logistic Regression with Regularization

# 6.- Advice for applying Machine Learning
#
#     6.1 Is h(x) OK? - evaluating the hypothesis function
#     6.2 Are the data sets OK? - Model selection & train/cv/test sets
#     6.3 Bias/Variance
#     	  6.3.1 Trade-off intuition 
# 	  6.3.2 Is 'd' OK? - Learning curves: 'd' selection
# 	  6.3.3 Is 'm' OK? - Learning curves: 'm' selection
# 	  6.3.4 Is λ OK? - Regularization & Bias/Variance: selecting λ
# 	  6.3.5 The decision process
#     6.4 Neural Networks Diagnosis FIXME_TODO

# 7.- Machine Learning systems design [2].page33
#
#     7.1 Error analysis
#     7.2 Error metrics for skewed classes: apply the Precision-Recall trade-off
#     7.3 How much data should we train?. Learning curves


# 8.- Some Machine Learning Problems 
#
#     8.1 Document Retrieval: similarity & clustering
#     	  8.1.1 How to measure similarity? - Bag of words model
# 	  8.1.2 Retrieving similar documents


# Hints

# Warnings

# Annex.- Maths Review

# Annex.- Linear Algebra Review

# Glossary 

# References

# Code examples


##==============================================================================

INFO notation   x sub i represented as  'x_i'

INFO notation   x super i represented as  'x^i'

INFO notation	Summation from i=1 to m represented as 'SUM_i=1_to_m'

INFO Notation 	theta can be represented as 'θ' is some equations.

INFO Notation 	h_theta can be represented as 'h' is some equations.

INFO Notation 	in vectorized notation, uppercase means MATRIX & lowercase means
     	      	scalar variable.

INFO Notation   Matrix: A' is the transpose matrix of A

INFO Notation   Matrix: inv(A) is the inverse matrix of A

INFO Notation   A /=> B: A does not implies B 


##==============================================================================
## 1.- Machine Learning methods to solve problems
##==============================================================================

##------------------------------------------------------------------------------
# 1.1 Linear Regression
##------------------------------------------------------------------------------

# 1.1.1 Linear Regression basics


NOTICE  Supervised learning model


a) To predict the actual CONTINUOUS valued output ('y/x' is a Gaussian
   distribution)

b) Multiple Linear Regression:                    y = f(x_1, .., x_n)

c) Simple Linear Regression (one variable l.r.):  y = f(x) ; M.L.R. where n=1


# 1.1.2 Problem description

a) Model representation

   Training set (x, y, m)   ->   i-th training example ( x(i), y(i) )

   m: number of examples
   n: number of features (n=1 in simple linear regression)
   x: inputs
   y: outputs

   X^i: i-th training example input

   X_j^i: i-th training example value of feature j

   Y^i: i-th training example output


b) Problem representation


         training set

             |
	     v

      learning algorithm

             |
	     v

 x  ->  h (hypothesis)  ->  y


c) hypothesis representation

   # simple linear regression (particular case, n=1)

   h_theta(x) = theta_0 + theta_1 * x


   # multiple linear regression (general case)

   h_theta(x) = theta_0 + theta_1 * x + .. + theta_n * x  =
   	      = SUM_i=1_to_n (theta_i * x_i)  ; x_0 = 1 


   INFO h_theta(x) can be notated as h(x) or just h.


d) Cost function 

   cost(h,y) = quadratic error = (h(x) - y)**2
   
   # multiple linear regression
   J(theta) = (1/2m)*cost(h,y) =  (1/2m) SUM_i=1_to_m(h(x^i ) - y^i)**2


e) Schema

   - Hypothesis:	h_theta(x)

   - Parameters:	theta_0, theta_1, .., theta_n

   - Cost Function:	J(theta)

   - Need: find the theta values to minimize J(theta), thus minimize the error
     	   between the real solution (y) and the approximated solution (h)

   - GOAL: use these values in h(x) to predict new solutions to new inputs.


   The Problem we need to solve is:  How to get theta values?

   -> we want software that automatically find theta values that minimize J
      (i.e) Gradient Descent algorithms.


##------------------------------------------------------------------------------
# 1.2. Logistic Regression
##------------------------------------------------------------------------------


NOTICE  Supervised learning model


# 1.2.1 Logistic Regression basics

a) Regression model where the dependent variable (DV) is categorical.

b) Logistic regression predicts the probability of particular outcomes -> to
   predict the actual DISCRETE valued output (i.e. {yes, no})

c) The conditional distribution 'y|x' is a Bernoulli distribution (y ∈ {0,1]),
   rather than a Gaussian distribution.


# 1.2.2 Linear Classifiers

Def Given an input X, a linear classifier IDENTIFY THE CLASS (y) it belongs to
    by making a classification decision based on the value of a LINEAR
    COMBINATION of the features of the input [4.6]

    y = f(θ . X)    # (scalar) dot product

    (i.e. Sentiment Analysis Problems using a Threshold classifier [3.2].p16)
     f(θ . X) >= threshold -> y = 1
     f(θ . X)  < threshold -> y = 0
     

# 1.2.3 Decision Boundary: What (classes) can h(x) represent?

Def A decision boundary is the region of a problem space in which the output
    label of a classifier is ambiguous [4.7]

- Decision boundary separates positive & negative predictions

  For linear classifiers:
   -> line: when 2 weights are non-zero
   -> plane: when 3 weights are non-zero
   -> hyperplane: when many weights are non-zero

  For more general classifiers -> more complicated shapes


HINT  Decicion boundary is a property of 'h_θ(x)',  it is not a property of 'X'

	i)   step 1: get θ	              
	ii)  step 2: get h
	iii) step 3: paint the plot of 'h_θ(x)', for several features of 'x'
	
	-> get the decision boundary (line, plane, ...) that separates positive
           & negative classes


# 1.2.4 Estimated (class) probabilities: how confident is a prediction?

HINT class probabilities are extremely useful in a practice

- Interpretation: h(x) = estimated prob. that y=1 on input x, given θ params.

  		  h(x) = P(y=1/x ; θ)

  Note: y ∈ {0, 1} => P(y=0/x; θ) = 1 - P(y=1/x; θ)
 


# 1.2.5 Classification Problem description

                                   | 0: negative class (non existence of)
a) Problem solution  ≡  y ∈ {0,1} < 
                                   | 1: positive class (existence of)


          | y ∈ {0, 1} : binary classification problem
b) Types < 
          | y ∈ {0, 1, 2, ..} : multiclass c.p.


c) hypothesis representation [2].11

 PROBLEM   h=θ.X is a BAD idea (1.2.1.c): y ∈ {0,1} ∀x  /=>  0 ≤ h(x) ≤ 1
    |
    v
 SOLUTION  h = Sigmoid Function: "g(z) = 1 / (1 +  e**(-z))"   [2].ML.C5, [4.2]

 	   g(z) = 1 / (1 +  e**(-z))   (1)

                            | ∈ [0, 0.5) if z<0
	   g(z) ∈ [0, 1] = <  0.5        if z=0     THRESHOLD
                            | ∈ (0.5, 1] if z>0


           h_θ(x) = g(θ'x) = 1/(1+e(-(θ'x)))


                         | 1  if g(z) ≥ THRESHOLD) iff z≥0
	   => h_θ(x) =  < 
                         | 0  otherwise



HINT Logistic Regression Cost Function (sigma) is convex => Gradient Descent
     algorithm ALWAYS converge to GLOBAL minimum


WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ

d) Cost function [2].13

PROBLEM sigmoid is not a linear function => many local minimums => linear
       Gradient Descent algorithm is not valid for logistic regression.


                 | -log h(x)  if y=1 |
   cost(h, y) = <                     > =  - y log(h) - (1-y)log(1-h)
                 | -log (1-h) if y=0 |


NOTICE linear vs logistic regression: the difference is only in h_θ(x)


    J(0) = (1/m) * cost(h,y)


# 1.2.6 Multiclass Classification: one-vs-all algorithm (method)

- Precondition: k-classes => k-logistic regression classification

- step 1: train a logistic regression classifier 'h_θ^i (x)' for each class
          'i' to predict p(y=i/x;θ)

- step 2: Given an input X, how to make a prediction?
       	  pick the class 'i' / max h_θ^i (x)
                                i

WARNING  ∑(h) > 1  is possible because different classes can intersect.



# 1.2.7 Miss-classification error [2].29

 Classification Error calculation for the test data set (X_test, y_test, m_test)

                    | 1   if ((h>=0.5) ∧ (y==0)) # predicted y=1 but actual y=0
		    |
                    | 1   if ((h<0.5) ∧ (y==1))  # predicted y=0 but actual y=1
  err(h_θ(x), y) = <
                    | 0   otherwise



  error = #mistakes / #total values	 # the best possible is 0
    
  accuracy = #correct / #total values = 1-error	# best possible is 1

  WARNING Accuracy is a bad index to evaluate skewed classes (always high)




##------------------------------------------------------------------------------
# 1.3 Clustering [2].41-42
##------------------------------------------------------------------------------

NOTICE  Unsupervised learning model

def (GOTO Glossary.Clustering)

- Main idea: instances in the same cluster are more similar to each other than
  those in others.

- Cluster analysis itself is not one specific algorithm, but the general task
  to be solved.

- Algorithm: k-means algorithm (GOTO 3.1)

- Problem application: DETECT SIMILARITIES (documents, images, illness, ...) ->
  structured search, product recommendation, grouping, ...

- Work-flow (unsupervised)
  - Training data = table(doc id, doc text)
  - Feature extraction = apply tf-idf(Training data) -> X = tf-idf
  - θ = cluster centers
  - h = estimated cluster label
  - ML model = clustering
  - ML algorithm = k-means
  - Quality metric = distance to cluster centers?



##------------------------------------------------------------------------------
# 1.4 Recommender Systems [3.4] [2].55-59
##------------------------------------------------------------------------------


NOTICE  Supervised learning model


# 1.4.1 Building a recommender system



1.4.?? Collaborative Filtering [2].57

Matrix factorization model


# 1.4.END Performance metric for recommender systems

  - Use precision & recall (GOTO 7.2): recommender systems only cares of the
    very few liked items -> skewed cases -> accuracy is a bad measure (GOTO
    warnings)


  a) Precision = True Pos. / (TP + FP)   # ( liked & recommended / recommended)

  b) Recall =    True Pos. / (TP + FN)   # ( liked & recommended / liked)


  Optimal recommender => precision = recall = 1
  
  



##==============================================================================
## 2.- Supervised Learning Algorithms
##==============================================================================


   Supervised Learning work-flow


  +---------------+   +--------------------+  X  +----------+  h
  | Training data |-->| Feature extraction |---->| ML model |-------->
  +---------------+   +--------------------+     +----------+    |
         |                                            ^          |
         | y                                          |          |
         |                                                       |
         |                                            θ          |
         |                                                       |
         |                                            ^          |
         |                                            |          |
         |                                    +--------------+   |
         |      		              | ML algorithm |   |
         |                                    +--------------+   |
         |                                            ^          |
         |                                            |          |
         |                                            |          |
         |                                  +----------------+   |
         +--------------------------------->| Quality Metric |<--+
                                            +----------------+   



##------------------------------------------------------------------------------
# 2.1 Gradient Descent Algorithm
##------------------------------------------------------------------------------

  NOTICE always using Batch G.D. (See Glossary)

- Resolution for:
  
  > Multiple Linear Regression [2].p5-6
  > Simple Linear Regression (multiple l. reg. where n=1) [2].ML.C3
  > Logistic Regression


  2.1.1 Equation

  # Notation note.- theta = θ
  # Notation note.- h_theta = h

  REPEAT
  {
    grad = (1/m) * ( SUM_i=1_to_m ( h( x^i ) - y^i ) * x_j^i )
    θ_j = θ_j - (α * grad)

    # i = 1 .. m: training example
    # j = 0 .. n: feature
    # x_0^i = 1 ∀ i
    # Batch GD: updating θ_j simultaneously# j = 0..n
    
  }


  2.1.2 Vectorized Notation (see glossary for details)

  	# INFO Notation in vectorized notation, uppercase means MATRIX &
  	# lowercase means scalar variable.
	# Exception: y is the solution vector (vector == n x 1 matrix )

  a) Linear Regression
  
     > h_theta(x) = X * θ


     > J(θ) =  (1/2m) (Xθ-y)' (Xθ-y)

       #INFO (Xθ-y)' * (Xθ-y) is just the error calculation, thus (h-y)**2,
       #     in matrix notation (scalar product).


     > grad = (1/m) * X' * (Xθ-y)
       θ = θ - (α * grad)


  b) Logistic Regression
  
     > h_θ(x) = g(Xθ)


     > J(θ) = 1/m ( log(g(Xθ))'y + log(1-g(Xθ))'(1-y) )


     > grad = (1/m) * X' * (g(Xθ)-y)  # logistic vs linear:  g(Xθ) vs Xθ
       θ = θ - (α * grad)


  2.1.3 Speeding up Gradient Descent

  	 - feature scaling technique (GOTO 4.1)
	 - mean normalization technique (GOTO 4.2)
	 - Polynomial Regression technique (GOTO 4.3)


  2.1.4 Debugging Gradient Descent [2].p7
  
  a) α selection for GD

    > Goal is to get the convergence curve as expected (3.c.1)

    > Proven: if α is small enough then J will decrease on every iteration
    > NG suggestion: decreasing α by multiples of 3:
      0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, ...

  b) Numbers of iterations: it is hard to predict ∀ problem.

  c) Correct Convergence Detection

    > Automatic convergence test (the correct in theory)

   	IF J(theta) <= Epsilon in one iteration THEN declare convergence

    > Plot of convergence (the easiest in practice)

   	(plot axis: θX = #iterations ; θY = J)
	Convergence iff curve form is the expected (fast fall - medium fall -
	almost flat)



##------------------------------------------------------------------------------
# 2.2. Normal Equation Method [2].p8
##------------------------------------------------------------------------------

- Mathematical (not AI) method to solve linear regression: finding the OPTIMAL
  theta values without iterations.


  θ = inv(X' * X) * X' * y   #WARNING computation order is θ(n**3)

  #INFO Octave notation: θ = pinv(X) * y 


- GD vs Normal Equation


          GD                vs        Normal Eq.
 ---------------------------|---------------------------
                            |
      Needs α           |          No α
                            |
  Needs many iterations     |        No iterations
                            |
         O(n)               |          O(n**3)           # WARNING key fact
 ---------------------------|---------------------------
 
           ||                             ||
           vv    ((according to Ng))      vv
	   
 ---------------------------|---------------------------	   
 OK for large n (n>=10**4)  |  OK for short n (n<10**4)  # CONCLUSION !!



##==============================================================================
## 3.- Unsupervised Learning Algorithms
##==============================================================================


   Unupervised Learning work-flow


  +---------------+   +--------------------+  X  +----------+  h
  | Training data |-->| Feature extraction |---->| ML model |-------->
  +---------------+   +--------------------+     +----------+    |
                                                    ^            |
                                                    |            |
                                                                 |
                                                    θ            |
                                                                 |
                                                    ^            |
                                                    |            |
                                              +--------------+   |
      		                              | ML algorithm |   |
                                              +--------------+   |
                                                    ^            |
                                                    |            |
                                                    |            |
                                            +----------------+   |
      		                            | Quality Metric |<--+
                                            +----------------+   



##------------------------------------------------------------------------------
# 3.1 k-means algorithm  [2].41-42
##------------------------------------------------------------------------------

a) Algorithm notes

   - μ_k: k-th centroid ; 1 ≤ k ≤ K

   - x^i: i-th example ; 1 ≤ i ≤ m

   - 'closest' ≡ norm(x-μ)^2 ≡    min  || x^i - μ_k ||^2   ~(Voronoi diagram)
                                 k=c^i

   - Convergence reached => after several iterations the clusters not affected
				

b) Steps

STEP_1	!Randomly! initiate K cluster centroids μ_1, μ_K ∈ R

STEP_2	REPEAT until Convergence{

  STEP_2_a "cluster assignment step": find closest centroid to each input var.

	  FOR i=1 TO m   // of the x-examples
	     c^i:= index (from 1 to k) of cluster centroids closest to x^i
	  END_FOR


  STEP_2_b "move centroids step"

	  FOR k=1 TO K   // of the K centroids 
	      IF k has zero points assigned
	      	 THEN remove k of random re-initiate it.
	      ELSE
		μ_k := average (mean) of the points assigned to cluster k
	      END_IF
	  END_FOR

	} # end_repeat


# 3.1.1 k-means for non-separated clusters

  a) Separated clusters: normal mode

  b) Non-separated clusters: i.e. t-shirts sizes: small, medium, large -> the
  clusters are contiguous.


# 3.1.2 Optimization objective


a) Cost function = J(c^1, c^m, μ_1, μ_k) = 1/m SUM_i=1_to_m || x^i - μ_c^i ||^2

 - Meaning: x^i has the c-kernel assigned

 - e.g.
   X set = {x_1, x_2, x_3} ; centroids = {μ_1, μ_2, μ_3}
   {x_1 -> μ_2 ; x_2 -> μ_2 ; x_3 -> μ_1
   then J = 1/3 ((x_1-μ_2)^2 + (x_2-μ_2)^2 + (x_3-μ_1)^2)


                                   | cluster assignment step: min J(x^1,.., x^m)
                                   |                          (μ fixed)
   min J(c, μ) = exec. k-mean alg.< 
   c,μ                             | 
                                   | move centroids step: min J(μ_1,.., μ_k)


HINT k-means ALWAYS converge (global or local minimum) [2].42

     - Using k-means J never can increase, although IT CAN FALL TO A LOCAL
       MINIMUM => apply random init. to reduce the probability of local min.


# 3.1.3 Random initialization of the centroids [e1]

  i)   Having k<m centroids
  ii)  RANDOMLY pick k training examples
  iii) Set μ_1, μ_2, μ_3 equal to theses examples

PROBLEM   How to avoid some (high) percentage of local minimum ?

SOLUTION i) run ONE ITERATION of the algorithm on many (50 to 100) random
	    initializations ...
	 ii) ... and then pick the one with min J(c, μ)


# 3.1.4 Choosing the number of clusters

HINT Too many clusters will over-fit the data (i.e. k==m)

* Usually k is selected by hand.

* automatic modes: "THE ELBOW METHOD"
  Fact: as k increase, J will always decrease
  - Ideal elbow evolution: linear fall + ~horiz fall => elbow point = k value
  - Actual elbow evolution: log. => no clear elbow
  
HINT Empirically tested that k must be ∈ [2-10]  [2].42


##==============================================================================
## 4.- Auxiliar techniques
##==============================================================================

# 4.1 Feature scaling [2].p6

    Xi = Xi / S    ; S = range(X)

    Used to speed up Gradient Descent Alg.


WARNING Feature scaling when S is close to 0
	(S ~= 0) iff vector feature ~= constant => bad feature => the feature
	must be removed => PROBLEM: S does not exists anymore.

  
# 4.2 Mean Normalization [2].p6

   Xi =  Xi / u   ; u =  mean(X)

   Used to speed up Gradient Descent Alg.


# 4.3 Polynomial Regression [2].p8

   h(x) = θ0 + θ1(x1) ...  ==>  h(x) = θ0 + θ1(x1) +  θ2 * sqrt(x1)

   	where (θ2 * sqrt(x1) ) is created to change the behaviour of the curve
   	to get a bettet fit of the solution (y)

   Used to improve the hypothesis function (h)

   INFO    d: polynomial degree of h(x)


# 4.4 Advanced Optimization [2].14, [3]video6.6_time=5:45

  - Using already known (libraries) learning algorithms: GD, L-BFG [4.3], BFGS
    [4.4], Conjugate gradient method [4.5], instead of programming one.

  WARNING Used in [3] with Octave code
  WARNING Used in [4] within the GraphLab tool.

  a) Input required for the algorithms: depends on the library / tool
     (i.e. Octave: code for 'grad', and code for J(θ))

  b) Plus 
     - Not needed to understand how they work, just use it (Octave libs).
     - α is calculated automatically.
     - Faster than manual algorithms.

  c) Minus
     - Complex than  manual algorithms.
     


##==============================================================================
# 5.- Regularization (solving the over-fitting problem)
##==============================================================================

# 5.1 Overfitting Problem (high variance - related to precision) [2].p17

  - Detection: h(x) match the training set almost perfectly.

  - Consequences: h(x) bad generalization.
  
  - Causes & solutions:

    i) Cause: too many features (n >> m). This means that some features are not
       representative to find the solution.

       Solution (-n): reduction of the number of features; manually or
       automatically (Model Selection algorithm)
       
       Solution (+m): add more training examples.
       
    ii) Cause: all the features are useful to find the solution, but the cost
    	function (J) is too much complex.

	Solution: Regularization


    WARNING First Mandatory action to get a solution: split the data set into:

    	    - training set (get Theta values)

	    - cross validation set (get λ, α, d, ...)

	    - test set (check the goodness of the algorithm)


# 5.2 Underfitting Problem (high bias - related to exactitude) [2].p17

  - Detection: h(x) does not fit the training set.

  - Consequences: h(x) bad generalization.
  
  - Causes & solutions:

    i) Cause: very few features (n << m). 

       Solution (+ n): add features.
       
    ii) Cause: cost function (J) is too much simple (i.e. h(x) = cte = 2)

    	Solution (+ d): increase the complexity of J (i.e. Polynomial Regression
    	technique)


# 5.3 Regularization [2].p17-20

  WHY Solution to overfitting problem caused by an excesive complex cost
      function, and when all the features are usefull to find the solution.

  HOW keep all the features but reduce the weight of some/every feature by
      incresing their cost.

  i) Decrease λ -> to fix0' high bias problem
  
  ii) Increase λ -> to fix high variance problem

  

##==============================================================================
# 6.- Advice for applying Machine Learning [2].page29-32
##==============================================================================

#INFO Notation: 'd' is the polynomial degree of h(x)


# 6.1 Is h(x) OK? - Evaluating the hypothesis function

  Overfitting => split the data in different sets: training, cv, test

  a) Error sets:
     - Training Error: X_train, y_train, m_train)
     - Cross validation Error: X_cv, y_cv, m_cv)
     - Test Error: X_test, y_test, m_test)

  b) Test Steps:
  
     i) Learn θ

     ii) Get J_train & J_vc (WITHOUT REGULARIZATION) to paint the learning
     	 curves to detect bias/variance errors.

     iii) Compute test set error (X_test, y_test, m_test), WITHOUT
     	  REGULARIZATION.

     	  Linear Error:   error(h,y) = 1/2m ∑((h-y)**2)

	  Logistic Error: error(h,y) = 1/2m ∑((h-y)**2)
	  	   	    OR
	  	   	  error(h,y) = miss-classification error (GOTO 1.2.4)

     iv) Compute the "Average Test Error" = 1/m ∑err(h,y)
     	     (X_test, y_test, m_test)


# 6.2 Are the data sets OK? - Model selection & train/cv/test sets

  We need to split the data set into three different sets:

  - training set (60%): used to optimize h (get Theta values)
  
  - cross validation set (20%): used to optimize other training parameters
    (λ, α, d, ...)

  - test set (20%): used to check the goodness of the solution
  

  WHY? Because J_training has been optimized for the training set -> J_training
       bad generalization.

       And because J_cv has been optimized for (e.g.) 'd' -> J_cv bad
       generalization.

       But the test set has not been used yet -> J_test good means that h(x)
       will have good generalization


  Goal: selection of the best polynomial degree for h(x)

  Steps:

  i)   Training set: ∀ 'd', min J_train = 1/2m SUM((h-y)**2)

  ii)  Cross Validation set:  ∀ 'd', min J_cv

  iii) Pick 'd' where J_cv is minimum

  iv)  Estimate generalization error for the test set: J_test(O^d_min)


# 6.3 Bias/Variance

  INFO High variance => over-fitting problem
  INFO High bias => under-fitting problem


# 6.3.1 Trade-off intuition 

  i) Complex Model (high polynomial degree) ->
     -> very sensitive to data ->
     -> highly affected by changes in X (input)

     => high variance & low bias

  i) Simple Model -> rigid -> lowly affected by changes in X (input)

     => low variance & high bias


HINT Models with less bias need more data to learn (initially slow learning ->
     curve slope linear instead of logarithmic), but do better with sufficient
     data (train-cv gap smaller)



# 6.3.2 Is 'd' OK? - Learning curves: 'd' selection

  - Plot (OX is 'd'; OY is J(theta))

    INFO J result high: means J value is distant to 0 

    INFO J result low: means J value is close to 0

  - Check the plot values of J_train & J_cv to check/find 'd'

  For any point in the plot, this is the meaning:
  
  case High bias: if (J_train ~= J_cv) and (both of them are high)

  case High variance: if (J_cv >> J_train ) and (J_train low)

  case optimal value for 'd': the lowest point for both J_train & J_cv where
       	       	     	      (J_train ~= J_cv)


# 6.3.3 Is 'm' OK? - Learning curves: 'm' selection

  - Plot (OX is 'm'; OY is J(theta))

  - Check the plot values of J_train & J_cv to check/find 'm'.

  For any point in the plot, this is the meaning:
  
  case High bias: if (J_train ~= J_cv) and (both of them are high)

  case High variance: if (J_cv >> J_train ) and (J_train low)


# 6.3.4 Is λ OK? - Regularization & Bias/Variance: selecting λ


# 6.3.5 The decision process

  a) Fixing high variance problem (over-fitting)

     ... by simplifying the model

     i)   (+l) Increase λ (in regularization).

     ii)  (-n) Remove some (non representatives) features.

     ... by adding training examples

     iii) (+m) Add training examples.


  b) Fixing high bias problem (under-fitting)
  
     ... by increasing the complexity of the model

     i)   (-l) Decrease λ (in regularization).

     ii)  (+n) Add features.

     iii) (+d) Add polynomial features.


     WARNING Adding training examples (+m) does not fix high bias.
     

# 6.4 Neural Networks Diagnosis


##==============================================================================
# 7.- Machine Learning systems design [2].page33
##==============================================================================

# 7.1 Error analysis:

- Recommended approach to solve a ML problem

  a) Start with a quick and dirty algorithm.
     > Test this alg. on the cross validation (cv) data set

  b) Plot learning curves to decide:
     > more data (+m) ?
     > more features (+n) ?
     > ...

  c) Error analysis: MANUALLY examine the errors on the cross validation (cv)
     data set to find systematic trends.

- Numerical evaluation: set a measure of your algorithm (%error, accuracy,
  ...), to see the results quickly.


# 7.2 Error metrics for skewed classes: apply Precision-Recall trade-off [4.1]

    - (Type of) Error Matrix

                                      True  class
		
                   |          1             |          0              |
                ---|--------------------------------------------------| 
                   |                        |                         |
    Predicted   1  |      True Positive     |   (FP) False Positive   |
                   |                        |                         |
                ---|--------------------------------------------------|
     class         |                        |                         |
                0  |   (FN) False Negative  |      True Negative      |
                   |                        |                         |
                ---|--------------------------------------------------|



    a) Precision =  True Positive / (TP + FP)    # ( TP / ∑ predicted 1s)

    b) Recall =     True Positive / (TP + FN)    # ( TP / ∑ true 1s)

    c) error =      #mistakes / #total values	 # the best possible is 0
    
    d) Accuracy =   ∑ true / ∑ total = (TP + TN) / (TP + TN + FP + FN)
       		=   #correct / #total values = 1-error	# best possible is 1

    e) Numerical evaluation: f1score = (2 * P * R) / (P + R)


HINT    Train P & R on the cv_set
                                          | inc threshold => inc P  &  dec R 
                                          |
HINT	Predict 1  if h(x) >= threshold  <
                                          | 
					  | dec theshold  => dec P  &  inc R


WARNING If we want to assure recall (i.e. to detect the max. number of skewed),
	then the precision tends to fall.

WARNING Accuracy is a bad index to evaluate skewed classes (always high)


HINT what accuracy does my application need?
     - What is good enough for my user’s experience?
     - What is the impact of the mistakes we make?


# 7.3 How much data should we train?

    a) Choose the correct features (X set) to have enough information:

       Given X, would a human expert predict y?

    b) First: get a low bias algorithm.
       Second: reduce overfiting and increase the accuracy of the training set.



##==============================================================================
# 8.- Some Machine Learning Problems 
##==============================================================================


##------------------------------------------------------------------------------
# 8.1 Document Retrieval: similarity & clustering
##------------------------------------------------------------------------------

Note.- corpus: large set of documents (i.e. library)


Issue_1 How to determine that two documents are similar? -> similarity 

Issue_2 How to retrieve similar documents -> clustering


# 8.1.1 How to measure similarity? - Bag of words model

  - Ignore order of words
  
  - Count # of instances of each word in vocabulary


 a) Problem representation

    + vector of words:
      - index i: i-th word of the document
      - v[i]: Count # of instances of each word

    + Measure similarity of 2 documents = similarity of the two vectors of
      words  v, w = ∑(v[i] * w[j])

      (e.g) v [1|0|0|5|3|0|0|1|0]
            w [3|0|0|2|0|0|1|0|0]   = 1*3 + 5*2 = 13


 b) Issues with words counts - Doc Length

      (i.e.) doc1 & doc2 with 2 pages / similarity = 1*3 + 5*2 = 13
      	     doc3=doc1 twice & doc4=doc2 twice:
	     	 -> expected similarity = 13 * 2 = 26
		 -> obtained similarity = 2*6 + 10*4 = 52

     SOLUTION = normalize => norm(vector) = vector / norm(vector)

      (e.g) v [1|0|0|5|3|0|0|1|0]  => v_norm [1/6|0|0|5/6|3/6|0|0|1/6|0]
            w [3|0|0|2|0|0|1|0|1]  => w_norm [3/√15|0|0|2/√15|0|0|1/√15|0|1/√15]

	    norm(v) = √(1^2 + 5^2 + 3^2 + 1^2) = 6
	    norm(w) = √(3^2 + 2^2 + 1^2 + 1^2) = √15

	    similarity (v_norm, w_norm) = 1/6*3/√15 + 5/6*2/√15 = 0.559


 c) Issues with words counts - rare words

    Note.- Rare globally: appears rarely in corpus

    Note.- Common locally:  appears frequently in document.

    - Rare word: rarely globally

    - Important word: common locally but rare globally.

    - We need to increase the importance of the rare words  to avoid loosing
      them.
   

   c.1) tf_idf: Term frequency – inverse document frequency

   	- (Measure) Trade off between local frequency and global rarity.

	- Common terms tend to disappear (tf-idf = 0)

   	- Important words tend to have a high tf-idf

	  => Words with highest TF-IDF are much more informative.


    (Equation)
    
    w: word
    d: doc
    D: corpus
    N: total number of documents in the corpus N = {|D|}
    |{d ∈ D: t ∈ d}|: number of documents where the term w appears

    • tf(w, d) = number of times word 'w' appeared in document 'd'
	 
    • idf(w, D) = log (N / (1 + |{d ∈ D: t ∈ d}|))
      #WARNING (1 + ...) to avoid division by zero if w ∉ D
      #INFO idf(Common words) tend to 0 because (log -> log 1 -> 0)

    • tf-idf(w, d, D) = tf(w.d) * idf(w,D)


   (e.g)
   Term frequency vector      tf = [ | |1000| | | |5 | | ]
   Inv doc frequency vector  idf = [ | | 0  | | | |4 | | ]
         tf-idf(w,d) = ∏(tf*idf) = [ | | 0  | | | |20| | ]



# 8.1.2 Retrieving similar documents

 a) Algorithm - Nearest neighbor search

    Problem representation

    + Input: Query article (a document)
    + Corpus: set of docs.
    + Specify: distance metric
    + Output: (list of k) most similar articles

    k - Nearest neighbor (k=1)

      	FOR each article 'a' in corpus
	    Compute s = similarity(query, a)
	    IF (s > best_s) THEN
	       add a to output
	       best_s = s
	    END_IF
	END_FOR

	return output


 b)  Algorithm - Clustering

    case 1: some classes are known ->  (supervised learning ) multiclass
    	    classification problem.

    case 2: unlabeled classes -> (unsupervised learning ) k-means algorithm.



##==============================================================================
## Hints
##==============================================================================


# convergence

HINT (Batch) Gradient Descent algorithm ALWAYS converge to GLOBAL minimum for
     linear regression problems. [2].ML.C3


HINT Logistic Regression Cost Function (sigma) is convex => Gradient Descent
     algorithm ALWAYS converge to GLOBAL minimum


HINT k-means ALWAYS converge, BUT not always to a global minimum. [2].42


# others

HINT (Batch) Gradient Descent algorithm scales better than the numerical method
     (Normal Equations Method), for large training sets (n>10000)


HINT Logistic Regression: class probabilities are extremely useful in a practice


HINT Why train/cv/test sets: (GOTO 6.2)


HINT Models with less bias need more data to learn (initially slow learning ->
     curve slope linear instead of logarithmic), but do better with sufficient
     data (train-cv gap smaller)


HINT  Decicion boundary is a property of 'h_θ(x)',  it is not a property of 'X'


##==============================================================================
## Warnings
##==============================================================================


WARNING Accuracy is a bad index to evaluate skewed classes (always high)


WARNING Feature scaling when S is close to 0
	(S ~= 0) iff vector feature ~= constant => bad feature => the feature
	must be removed => PROBLEM: S does not exists anymore.


WARNING Multiple Regression vs Multivariate Regression
	Multiple Regression:      y = f(X1, .., Xn)
	Multivariate Regression:  f(Y1, .., Yn) = f(X1, .., Xn)


WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ



##==============================================================================
## Annex.- Maths Review
##==============================================================================



##==============================================================================
## Annex.- Linear Algebra Review
##==============================================================================



##==============================================================================
## Annex.- Glossary 
##==============================================================================

A


B

- Batch Gradient Descent algorithm: for every iteration step of the GD
  algorithm, we SIMULTANEOUSLY use (update) the entire training set.


C

- Classification Problem: to predict the actual DISCRETE valued output
  (i.e. {yes, no})
  
- Clustering (Cluster analysis): cluster analysis or clustering is the task of
  grouping a set of objects in such a way that objects in the same group
  (called a cluster) are more similar (in some sense or another) to each other
  than to those in other groups (clusters). Cluster analysis itself is not one
  specific algorithm, but the general task to be solved. [4.8]


- Cost function: function to get the learning algorithm result.
  i.e. in linear regression this is the function to minimize

- cv: cross validation set


G

- Gaussian Distribution (Normal Distribution) [2].page.ML_C5

  x ~ N(μ,σ2)

  o: desviación típica
  o**2: varianza


L

- Labeled data: data for which we know its value, thus, given a X data set, it
  is labeled iff we also know Y.
  Used to evaluate the system: cv_set and test_set.


N

- Non invertibility Problem [2].p9: Matrix non invertible -> can not be used to
  GD calculation.
  Cause -> Solution: feature redundancy -> remove the dependent feature
  Cause -> Solution: (n >= m) -> remove some features or regularization.
  INFO In Octave, pinv(X) ALWAYS calculates the inverse matrix of X.

- Normal Equation Method: mathematical (not AI) method to solve linear
  regression. This method is suggested for low size training sets.


O

- Ordinary Least Squares (OLS): method for estimating the unknown parameters in
  a (linear) regression problem


P

- Precision: see 4.4


R

- Recall: see 4.4

- Regression Problem: predict the actual CONTINUOUS valued output.

- RMSE: Root-mean-square error (or r-m-s deviation) -
  https://en.wikipedia.org/wiki/Root-mean-square_deviation


S

- Sentiment analysis (also known as opinion mining) refers to the use of
  natural language processing, text analysis and computational linguistics to
  identify and extract subjective information in source materials. (wiki)
  Logistic Regression is used to solve sentiment analysis.

- Sigmoid Function: "g(z) = 1 / (1 +  e**(-z))"   [2].ML.C5, [4.2]
  Cost function used to solve logistic (classification) regression problems.
  WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ


- Skewed classes: classes that are very rare in the data set.
  (e.g) rain vs not rain -> 50% / 50% -> no skewed
  	cancer vs not cancer -> 0.05% / 99.5% -> cancer is a skewed class
  Skewed classes can be evaluated using the Precision/Recall technique (see 4.4)
  WARNING Accuracy is a bad index to evaluate skewed classes (always high)

- Supervised Learning (Algorithms): for every example of the data set, we are
  provided with the "correct answer" to predict. Thus, the training example
  sets are provided to the algorithm.


U

- Unsupervised Learning (Algorithms): neither the training set, nor the possible
  solution are provided to the algorithm. The algorithm itself make its own
  conclusions as a result to an input; and later the human engineer will study
  this conclusions.


V

- Vectorized Notation (or Matrix Notation): used to optimize the speed of the
  calculations.
  Relies on the mathematical software libraries used: using the library's
  matrix operations instead of manual programming using "for loops".
  The speed up can be in order of hundreds (empirically tested)


##==============================================================================
## References
##==============================================================================

[1] Machine Learning course - U. Stanford (Andrew Ng)

[2] Notest at the ML (paper) notebook.

[3] Machine Learning course - U.Washington
[3.1] regression problems - 1.regression-intro-annotated.pdf 
[3.2] classification problems - 2.classification-annotated.pdf
[3.3] clustering problems - 3.clustering-intro-annotated.pdf
[3.4] recommender systems - 4.recommenders-intro-annotated.pdf

[4] Wikipedia
[4.1] Precision/Recall - https://en.wikipedia.org/wiki/Precision_and_recall
[4.2] Sigmoid function - https://en.wikipedia.org/wiki/Sigmoid_function
[4.3] L-BFGS algorithm - https://es.wikipedia.org/wiki/L-BFGS
[4.4] BFGS algorithm - https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm
[4.5] Conjugate gradient method - https://en.wikipedia.org/wiki/Conjugate_gradient_method
[4.6] Linear classifier - https://en.wikipedia.org/wiki/Linear_classifier
[4.7] Decision boundary - https://en.wikipedia.org/wiki/Decision_boundary
[4.8] Clustering - https://en.wikipedia.org/wiki/Cluster_analysis

[5] Other Web references


##==============================================================================
## Code examples
##==============================================================================

[e1] k-means random initialization - /curso_stanford/programming_exercices/ex7.week8/mlclass-ex7/kMeansInitCentroids.m





#######################################
# http://www.rapidtables.com/math/symbols/Basic_Math_Symbols.htm
#######################################
# ∀
# ∏
# ∑
#######################################
# ∃
# ∈
# ∉
# ∩
# ∧
# ε
# ∇
#######################################
# α
# β
# λ
# θ theta
# δ delta
# π
# σ sigma
# ∇ gradient
# N(μ,σ2)
# μ mu
#######################################
# ∝
# ∞
# √
# ≈
# ≤
# ≥
# ±
# ⊂
# ≡
# ±
# ∓
#######################################
# •
#######################################
