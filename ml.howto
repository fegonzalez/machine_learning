

##==============================================================================
## INDEX
##==============================================================================

# 1.- Types of Problems
#
#     1.1 Regression Problems
#     	   1.1.1 Linear Regression (one variable regression)
# 	   1.1.2 Multivariate Regression
#     1.2 Classification Problems


# 2.- Supervised Learning Algorithms
#
#     2.1. Gradient Descent Algorithm
#     	   2.1.1 Equation
#     	   2.1.2 Vectorized Notation
#     	   2.1.3 Speeding up Gradient Descent
#     	   2.1.4 Debugging Gradient Descent [2.6]

# 3.- Unsupervised Learning Algorithms
#


# 4.- Techniques
#
#     4.1 Feature scaling  
#     4.2 Mean Normalization
#     4.3 Polynomial Regression


# 5.- Regularization (solving the over-fitting problem)
#
#     5.1 Overfitting Problem (high variance)
#     5.2 Underfitting Problem (high bias)
#     5.3 Regularization
#     5.4 Regularized Linear Regression
#     	   5.4.4.1 Vectorized Linear Regression with Regularization
#     5.5 Regularized Normal Equation
#     5.6 Regularized Logistic Regression
#     	   5.4.6.1 Vectorized Logistic Regression with Regularization


# 6.- Advice for applying Machine Learning FIXME_TODO
#
#     6.1 Is h(x) OK? - evaluating the hypothesis function
#     6.2 Are the data sets OK? - Model selection & train/cv/test sets
#     6.3 Bias/Variance
#     	  6.3.1 Trade-off intuition 
# 	  6.3.2 Is 'd' OK? -  Bias & Variance diagnosis : 'd' selection
# 	  6.3.3 Is 'm' OK? - Learning curves: 'm' selection
# 	  6.3.4 Is lambda OK? - Regularization & Bias/Variance: selecting lambda
# 	  6.3.5 The decision process
#     6.4 Neural Networks Diagnosis FIXME_TODO

# 7.- Machine Learning systems design [2.10] FIXME_TODO
#
#     7.1 Error analysis:
#     7.2 Error metrics for skewed classes:
#     7.3 Precision-Recall trade-off
#     7.4 How much data should we train?


# Hints

HINT Why train/cv/test sets: GOTO 6.2


# Warnings

# Annex.- Maths Review

# Annex.- Linear Algebra Review

# Glossary 

# References

##==============================================================================



##==============================================================================
## 1.-   Types of Problems
##==============================================================================


INFO notation   x sub i represented as  'x_i'

INFO notation   x super i represented as  'x((i))'

INFO notation	Summation from i=1 to m represented as 'SUM_i=1_to_m'

INFO Notation 	theta can be represented as 'O' is some equations.

INFO Notation 	h_theta can be represented as 'h' is some equations.

INFO Notation 	in vectorized notation, uppercase means MATRIX & lowercase means
     	      	scalar variable.

INFO Notation   Matrix: A' is the transpose matrix of A

INFO Notation   Matrix: inv(A) is the inverse matrix of A


##------------------------------------------------------------------------------
# 1.1. Regression Problems
##------------------------------------------------------------------------------

  To predict the actual CONTINUOUS valued output.

# 1.1.1. Linear Regression (one variable regression):  y = f(X)

# 1.1.2. Multivariate Regression:                      y = f(X1, .., Xn)

  	 n = 1: linear regression



a) Model representation

   Training set (x, y, m)   ->   i-th training example ( x(i), y(i) )

   m: number of examples
   n: number of features (n=1 in linear regression)
   x: inputs
   y: outputs

   X((i)): i-th training example input

   X_j((i)): i-th training example value of feature j

   Y((i)): i-th training example output


b) Problem representation


         training set

             |
	     v

      learning algorithm

             |
	     v

 x  ->  h (hypothesis)  ->  y


c) hypothesis representation

   h_theta(x) = theta_0 + theta_1 * x  # linear regression (n=1)

   INFO h_theta(x) can be notated as h(x)


d) Cost function 

   # linear regression (particular case, n=1)
   J(theta_0, theta_1) = 1/(2m) * SUM_i=1_to_m ( h( x((i)) ) - y((i)) ) **2

   # multivariate regression (general case)


e) Schema

   - Hypothesis:	h_theta(x)

   - Parameters:	theta_0, theta_1, .., theta_n

   - Cost Function:	J(theta)

   - GOAL:		find theta values to minimize J(theta)


   The Problem is  How to get theta values?

   -> we want software that automatically find theta values that minimize J
      (i.e) Gradient Descent algorithms


##------------------------------------------------------------------------------
# 1.2. Classification Problems
##------------------------------------------------------------------------------

  To predict the actual DISCRETE valued output (i.e. {yes, no})




##==============================================================================
## 2.- Supervised Learning Algorithms
##==============================================================================

##------------------------------------------------------------------------------
# 2.1. Gradient Descent Algorithm
##------------------------------------------------------------------------------

  NOTICE always using Batch G.D. (See Glossary)

- Resolution for:
  
    > Multivariate Regression [2.3]
    > Linear Regression with one variable (multivariate reg. where n=1) [2.1]


  2.1.1 Equation

  # Notation note.- theta = O
  # Notation note.- h_theta = h

  REPEAT
  {
    grad = (1/m) * ( SUM_i=1_to_m ( h( x((i)) ) - y((i)) ) * x_j((i)) )
    O_j = O_j - (alpha * grad)

    # Batch GD: updating O_j simultaneously# j = 0..n
    # x_0((i)) = 1 for every i
    
  }


  2.1.2 Vectorized Notation (see glossary for details)

  	# INFO Notation in vectorized notation, uppercase means MATRIX &
  	# lowercase means scalar variable.


	> h(x) = X * O


	> J(O) =  (1/2m) (XO-y)' (XO-y)

	  #INFO (XO-y)' * (XO-y) is just the error calculation, thus (h-y)**2,
	  #     in matrix notation (scalar product).


	> O = O - (alpha * grad)

	  # grad = (1/m) * X' * (XO-y)


  2.1.3 Speeding up Gradient Descent

  	 - feature scaling technique (GOTO 4.1)
	 - mean normalization technique (GOTO 4.2)
	 - Polynomial Regression technique (GOTO 4.3)


  2.1.4 Debugging Gradient Descent [2.6]
  
  a) alpha selection for GD

    > Goal is to get the convergence curve as expected (3.c.1)
    > Proven: if alpha is small enough then J will decrease on every iteration
    > NG suggestion: decreasing alpha by multiples of 3:
      0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, ...

  b) Numbers of iterations: it is hard to predict for every problem.

  c) Correct Convergence Detection

    > Automatic convergence test (the correct in theory)

   	IF J(theta) <= Epsilon in one iteration THEN declare convergence

    > Plot of convergence (the easy in practice)

   	(OX = #iterations ; OY = J)
	Convergence iff curve form is the expected (fast fall - medium fall -
	almost flat)



##------------------------------------------------------------------------------
# 2.2. Normal Equation Method [2.2]
##------------------------------------------------------------------------------

- Mathematical (not AI) method to solve linear regression: finding the optimal
  theta values without iterations.


  O = inv(X' * X) * X' * y   #WARNING computation order is O(n**3)

  #INFO Octave notation: O = pinv(X) * y 


- GD vs Normal Equation


          GD                vs        Normal Eq.
 ---------------------------|---------------------------
                            |
      Needs alpha           |          No alpha
                            |
  Needs many iterations     |        No iterations
                            |
         O(n)               |          O(n**3)           # WARNING key fact
 ---------------------------|---------------------------
 
           ||                             ||
           vv    ((according to Ng))      vv
	   
 ---------------------------|---------------------------	   
 OK for large n (n>=10**4)  |  OK for short n (n<10**4)  # CONCLUSION !!



##==============================================================================
## 3.- Unsupervised Learning Algorithms
##==============================================================================



##==============================================================================
## 4.- Techniques
##==============================================================================

4.1. Feature scaling [2.5]

    Xi = Xi / S    ; S = range(X)

    Used to speed up Gradient Descent Alg.


WARNING Feature scaling when S is close to 0
	(S ~= 0) iff vector feature ~= constant => bad feature => the feature
	must be removed => PROBLEM: S does not exists anymore.

  
4.2. Mean Normalization [2.5]

   Xi =  Xi / u   ; u =  mean(X)

   Used to speed up Gradient Descent Alg.


4.3. Polynomial Regression [2.4]

   h(x) = O0 + O1(x1) ...  ==>  h(x) = O0 + O1(x1) +  O2 * sqrt(x1)

   	where (O2 * sqrt(x1) ) is created to change the behaviour of the curve
   	to get a bettet fit of the solution (y)

   Used to improve the hypothesis function (h)

   INFO    d: polynomial degree of h(x)


##==============================================================================
# 5.- Regularization (solving the over-fitting problem)
##==============================================================================

# 5.1. Overfitting Problem (high variance - related to precision) [2.8]

  - Detection: h(x) match the training set almost perfectly.

  - Consequences: h(x) bad generalization.
  
  - Causes & solutions:

    i) Cause: too many features (n >> m). This means that some features are not
       representative to find the solution.

       Solution (-n): reduction of the number of features; manually or
       automatically (Model Selection algorithm)
       
       Solution (+m): add more training examples.
       
    ii) Cause: all the features are useful to find the solution, but the cost
    	function (J) is too much complex.

	Solution: Regularization


    WARNING First Mandatory action to get a solution: split the data set into:
    	    - training set
	    - cross validation set
	    - test set


# 5.2. Underfitting Problem (high bias - related to exactitude) [2.8]

  - Detection: h(x) does not fit the training set.

  - Consequences: h(x) bad generalization.
  
  - Causes & solutions:

    i) Cause: too few features (n << m). 

       Solution (+ n): add features.
       
    ii) Cause: cost function (J) is too much simple (i.e. h(x) = cte = 2)

    	Solution (+ d): increase the complexity of J (i.e. Polynomial Regression
    	technique)


# 5.3. Regularization [2.8]

  WHY Solution to overfitting problem caused by an excesive complex cost
      function, and when all the fer¡tures are usefull to find the solution.

  HOW keep all the features but reduce the weight of some/every feature by
      incresing their cost.

  i) Decrease lambda -> to fix high bias problem
  
  ii) Increase lambda -> to fix high variance problem

  

##==============================================================================
# 6.- Advice for applying Machine Learning [2.9]
##==============================================================================

#INFO Notation: 'd' is the polynomial degree of h(x)


# 6.1 Is h(x) OK? - Evaluating the hypothesis function FIXME_TODO

  Overfitting => split the data in different sets: training, cv, tesst


# 6.2 Are the data sets OK? - Model selection & train/cv/test sets

  We need to split the data set into three different sets:
  
  - training set (60%): used to optimize h(x)
  
  - cross validation set (20%): used to optimize other training parameters (d,
    lambda, ...)

  - test set (20%): used to check the resulting cost function.
  

  WHY? Because J_training has been optimized for the training set -> J_training
       bad generalization.

       And because J_cv has been optimized for (e.g.) 'd' -> J_cv bad
       generalization.

       But the test set has not been used yet -> J_test good generalization


  Goal: selection of the best polynomial degree for h(x)

  Steps:

  i)   Training set: for every 'd', min J_train = 1/2m SUM((h-y)**2)

  ii)  Cross Validation set:  for every 'd', min J_cv

  iii) Pick 'd' where J_cv is minimum

  iv)  Estimate generalization error for the test set: J_test(O((d_min)))


# 6.3 Bias/Variance

  INFO High variance => over-fitting problem
  INFO High bias => under-fitting problem


# 6.3.1 Trade-off intuition 

  i) Complex Model (high polynomial degree) ->
     -> very sensitive to data ->
     -> highly affected by changes in X (input)

     => high variance & low bias


  i) Simple Model -> rigid -> lowly affected by changes in X (input)

     => low variance & high bias


# 6.3.2 Is 'd' OK? -  Bias & Variance diagnosis : 'd' selection

  - Plot (OX is 'd'; OY is J(theta))

    INFO J result high: means J value is distant to 0 

    INFO J result low: means J value is close to 0

  - Check the plot values of J_train & J_cv to check/find 'd'

  For any point in the plot, this is the meaning:
  
  case High bias: if (J_train ~= J_cv) and (both of them are high)

  case High variance: if (J_cv >> J_train ) and (J_train low)

  case optimal value for 'd': the lowest point for both J_train & J_cv where
       	       	     	      (J_train ~= J_cv)


# 6.3.3 Is 'm' OK? - Learning curves: 'm' selection

  - Plot (OX is 'm'; OY is J(theta))

  - Check the plot values of J_train & J_cv to check/find 'm'.

  For any point in the plot, this is the meaning:
  
  case High bias: if (J_train ~= J_cv) and (both of them are high)

  case High variance: if (J_cv >> J_train ) and (J_train low)


# 6.3.4 Is lambda OK? - Regularization & Bias/Variance: selecting lambda


# 6.3.5 The decision process

  a) Fixing high variance problem (over-fitting)

     i)   (+l) Increase lambda (in regularization).

     ii)  (-n) Remove some (non representatives) features.

     iii) (+m) Add training examples.

  b) Fixing high bias problem (under-fitting)

     i)   (-l) Decrease lambda (in regularization).

     ii)  (+n) Add features.

     iii) (+d) Add polynomial features.


     WARNING Adding training examples (+m) does not fix high bias.
     

# 6.4 Neural Networks Diagnosis


##==============================================================================
# 7.- Machine Learning systems design [2.10] FIXME_TODO
##==============================================================================

7.1 Error analysis:

- Recommended approach to solve a ML problem

  a) Start with a quick and dirty algorithm.
     Test this alg. on the cross validation (cv) data set

  b) Plot learning curves to decide:
     > more data (+m) ?
     > more features (+n) ?
     > ...

  c) Error analysis: MANUALLY examine the errors on the cross validation (cv)
     data set to find systematic trends.

- Numerical evaluation: set a measure of your algorithm (%error, accuracy,
  ...), to see the results quickly.


7.2 Error metrics for skewed classes:


7.3 Precision-Recall trade-off


7.4 How much data should we train?

    a) Choose the correct features (X set) to have enough information:

       Given X, would a human expert predict y?

    b) Once having a low bias algorithm, then enlarge the training set to
       reduce overfitting and increase the accuracy of the training set



##==============================================================================
## Hints
##==============================================================================

HINT (Batch) Gradient Descent algorithm ALWAYS converge to GLOBAL minimum for
     linear regression problems. [2.1]

HINT (Batch) Gradient Descent algorithm scales better than the numerical method
     (Normal Equations Method), for large training sets.


##==============================================================================
## Warnings
##==============================================================================

WARNING Feature scaling when S is close to 0
	(S ~= 0) iff vector feature ~= constant => bad feature => the feature
	must be removed => PROBLEM: S does not exists anymore.


WARNING Multiple Regression vs Multivariate Regression
	Multiple Regression:      y = f(X1, .., Xn)
	Multivariate Regression:  f(Y1, .., Yn) = f(X1, .., Xn)



##==============================================================================
## Annex.- Maths Review
##==============================================================================


##==============================================================================
## Annex.- Linear Algebra Review
##==============================================================================



##==============================================================================
## Annex.- Glossary 
##==============================================================================

A

B

- Batch Gradient Descent algorithm: for every iteration step of the GD
  algorithm, we SIMULTANEOUSLY use (update) the entire training set.

C

- Classification Problem: to predict the actual DISCRETE valued output
  (i.e. {yes, no})
  
- Cost function: function to get the learning algorithm result.
  i.e. in linear regression this is the function to minimize

- cv: cross validation set

N

- Non invertibility Problem [2.7]: Matrix non invertible -> can not be used to
  GD calculation.
  Cause -> Solution: feature redundancy -> remove the dependent feature
  Cause -> Solution: (n >= m) -> remove some features or regularization.
  INFO In Octave, pinv(X) ALWAYS calculates the inverse matrix of X.

- Normal Equation Method: mathematical (not AI) method to solve linear
  regression. This method is suggested for low size training sets.


O

- Ordinary Least Squares (OLS): method for estimating the unknown parameters in
  a (linear) regression problem


R

- Regression Problem: predict the actual CONTINUOUS valued output.


S

- Sigmoid Function [2].ML.C5 : cost function used to solve logistic
  (classification) regression problems.

- Supervised Learning (Algorithms): for every example of the data set, we are
  provided with the "correct answer" to predict. Thus, the training example
  sets are provided to the algorithm.


U

- Unsupervised Learning (Algorithms): neither the training set, nor the possible
  solution are provided to the algorithm. The algorithm itself make its own
  conclusions as a result to an input; and later the human engineer will study
  this conclusions.


V

- Vectorized Notation (or Matrix Notation): used to optimize the speed of the
  calculations.
  Relies on the mathematical software libraries used: using the library's
  matrix operations instead of manual programming using "for loops".
  The speed up can be in order of hundreds (empirically tested)


##==============================================================================
## References
##==============================================================================

[1] Machine Learning course - U. Stanford (Andrew Ng)

[1.1] Using Python on a Macintosh - https://docs.python.org/3.3/using/mac.html


[2] Notest at the ML (paper) notebook.

[2.1] (Batch) Gradient Descent algorithm - page ML.C3
[2.2] Normal Equation Method - page 8
[2.3] Multivariate Regression - pages 5-6
[2.4] Features and Polynomial Regression - page 8
[2.5] Speeding up Gradient Descent - page 6
[2.6] Debugging Gradient Descent - page 7
[2.7] Non invertibility Problem - page 9
[2.8] Regularization
[2.9] Advice for applying Machine Learning - pages 29-32
[2.10] Machine Learning systems design - pages 33


[3] Machine Learning course - U.Washington

