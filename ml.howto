

##==============================================================================
## INDEX
##==============================================================================

# 1.- Types of Problems
#
#     1.1 Regression Problems
#     	   1.1.1 Linear Regression (one variable regression)
# 	   1.1.2 Multivariate Regression
#     1.2 Classification Problems
#     	  1.2.1 Estimated (class) probabilities: how confident is a prediction?
#     	  1.2.2 Decision Boundary: What can h(x) represent?
#     	  1.2.3 Multiclass Classification: one-vs-all algorithm (method)

# 2.- Supervised Learning Algorithms
#
#     2.1. Gradient Descent Algorithm
#     	   2.1.1 Equation
#     	   2.1.2 Vectorized Notation
#     	   2.1.3 Speeding up Gradient Descent
#     	   2.1.4 Debugging Gradient Descent [2].p7

# 3.- Unsupervised Learning Algorithms
#


# 4.- Techniques
#
#     4.1 Feature scaling  
#     4.2 Mean Normalization
#     4.3 Polynomial Regression
#     4.4 Advanced Optimization

# 5.- Regularization (solving the over-fitting problem)
#
#     5.1 Overfitting Problem (high variance)
#     5.2 Underfitting Problem (high bias)
#     5.3 Regularization
#     5.4 Regularized Linear Regression
#     	   5.4.4.1 Vectorized Linear Regression with Regularization
#     5.5 Regularized Normal Equation
#     5.6 Regularized Logistic Regression
#     	   5.4.6.1 Vectorized Logistic Regression with Regularization


# 6.- Advice for applying Machine Learning FIXME_TODO
#
#     6.1 Is h(x) OK? - evaluating the hypothesis function
#     6.2 Are the data sets OK? - Model selection & train/cv/test sets
#     6.3 Bias/Variance
#     	  6.3.1 Trade-off intuition 
# 	  6.3.2 Is 'd' OK? - Learning curves: 'd' selection
# 	  6.3.3 Is 'm' OK? - Learning curves: 'm' selection
# 	  6.3.4 Is λ OK? - Regularization & Bias/Variance: selecting λ
# 	  6.3.5 The decision process
#     6.4 Neural Networks Diagnosis FIXME_TODO

# 7.- Machine Learning systems design [2].page33 FIXME_TODO
#
#     7.1 Error analysis:
#     7.2 Error metrics for skewed classes: apply the Precision-Recall trade-off
#     7.3 How much data should we train?. Learning curves


# Hints

# Warnings

# Annex.- Maths Review

# Annex.- Linear Algebra Review

# Glossary 

# References

##==============================================================================

INFO notation   x sub i represented as  'x_i'

INFO notation   x super i represented as  'x((i))'

INFO notation	Summation from i=1 to m represented as 'SUM_i=1_to_m'

INFO Notation 	theta can be represented as 'θ' is some equations.

INFO Notation 	h_theta can be represented as 'h' is some equations.

INFO Notation 	in vectorized notation, uppercase means MATRIX & lowercase means
     	      	scalar variable.

INFO Notation   Matrix: A' is the transpose matrix of A

INFO Notation   Matrix: inv(A) is the inverse matrix of A

INFO Notation   A /=> B: A does not implies B 


##==============================================================================
## 1.-   Types of Problems
##==============================================================================


##------------------------------------------------------------------------------
# 1.1. Regression Problems
##------------------------------------------------------------------------------

  To predict the actual CONTINUOUS valued output.

# 1.1.1. Linear Regression (one variable regression):  y = f(X)

# 1.1.2. Multivariate Regression:                      y = f(X1, .., Xn)


a) Model representation

   Training set (x, y, m)   ->   i-th training example ( x(i), y(i) )

   m: number of examples
   n: number of features (n=1 in linear regression)
   x: inputs
   y: outputs

   X((i)): i-th training example input

   X_j((i)): i-th training example value of feature j

   Y((i)): i-th training example output


b) Problem representation


         training set

             |
	     v

      learning algorithm

             |
	     v

 x  ->  h (hypothesis)  ->  y


c) hypothesis representation

   # linear regression (particular case, n=1)

   h_theta(x) = theta_0 + theta_1 * x


   # multivariate regression (general case)

   h_theta(x) = theta_0 + theta_1 * x + .. + theta_n * x  =
   	      = SUM_i=1_to_n (theta_i * x_i)  ; x_0 = 1 


   INFO h_theta(x) can be notated as h(x) or just h.


d) Cost function 

   cost(h,y) = quadratic error = (h(x) - y)**2
   
   # multivariate regression (general case)
   J(theta) = (1/2m)*cost(h,y) =  (1/2m) SUM_i=1_to_m(h(x((i)) ) - y((i)))**2


e) Schema

   - Hypothesis:	h_theta(x)

   - Parameters:	theta_0, theta_1, .., theta_n

   - Cost Function:	J(theta)

   - Need: find the theta values to minimize J(theta), thus minimize the error
     	   between the real solution (y) and the approximated solution (h)

   - GOAL: use these values in h(x) to predict new solutions to new inputs.


   The Problem we need to solve is:  How to get theta values?

   -> we want software that automatically find theta values that minimize J
      (i.e) Gradient Descent algorithms.


##------------------------------------------------------------------------------
# 1.2. Classification Problems
##------------------------------------------------------------------------------

  To predict the actual DISCRETE valued output (i.e. {yes, no})


                                   | 0: negative class (non existence of)
a) Problem solution  ≡  y ∈ {0,1} < 
                                   | 1: positive class (existence of)


          | y ∈ {0, 1} : binary classification problem
b) Types < 
          | y ∈ {0, 1, 2, ..} : multiclass c.p.


c) hypothesis representation [2].11

 PROBLEM   Gradient Descent is a BAD idea: y ∈ {0,1} ∀x  /=>  0 ≤ h(x) ≤ 1
    |
    v
 SOLUTION  Sigmoid Function: "g(z) = 1 / (1 +  e**(-z))"   [2].ML.C5, [4.2]

 	   g(z) = 1 / (1 +  e**(-z))   (1)

                            | ∈ [0, 0.5) if z<0
	   g(z) ∈ [0, 1] = <  0.5        if z=0
                            | ∈ (0.5, 1] if z>0


           h_θ(x) = g(θ'x) = 1/(1+e(-(θ'x))) 


HINT Logistic Regression Cost Function (sigma) is convex => Gradient Descent
     algorithm ALWAYS converge to GLOBAL minimum


WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ

d) Cost function [2].13

PROBLEM sigmoid is not a linear function => many local minimums => linear
       Gradient Descent algorithm is not valid for logistic regression.


                 | -log h(x)  if y=1 |
   cost(h, y) = <                     > =  - y log(h) - (1-y)log(1-h)
                 | -log (1-h) if y=0 |


NOTICE linear vs logistic regression: the difference is only in h_θ(x)


    J(0) = (1/m) * cost(h,y)


1.2.1 Estimated (class) probabilities: how confident is a prediction?

HINT class probabilities are extremely useful in a practice

- Interpretation: h(x) = estimated prob. that y=1 on input x, given θ params.

  		  h(x) = P(y=1/x ; θ)

  Note: y ∈ {0, 1} => P(y=0/x; θ) = 1 - P(y=1/x; θ)
 

1.2.2 Decision Boundary: What can h(x) represent?

NOTICE  D.B. is a property of 'h_θ(x)' ; it is not a property of 'x'

	First:  get θ |
	               >  --> get decision boundaries
	Second: get h |


1.2.3 Multiclass Classification: one-vs-all algorithm (method)

- Precondition: k-classes => k-logistic regression classification

- step 1: train a logistic regression classifier 'h_θ((i)) (x)' for each class
          'i' to predict p(y=i/x;θ)

- step 2: Given an input X, how to make a prediction?
       	  pick the class 'i' / max h_θ((i)) (x)
                                i

WARNING  ∑(h) > 1  is possible because different classes can intersect.


1.2.4 Miss-classification error [2].29

 Classification Error calculation for the test data set (X_test, y_test, m_test)

                    | 1   if ((h>=0.5) ∧ (y==0)) # predicted y=1 but actual y=0
		    |
                    | 1   if ((h<0.5) ∧ (y==1))  # predicted y=0 but actual y=1
  err(h_θ(x), y) = <
                    | 0   otherwise


##==============================================================================
## 2.- Supervised Learning Algorithms
##==============================================================================

##------------------------------------------------------------------------------
# 2.1. Gradient Descent Algorithm
##------------------------------------------------------------------------------

  NOTICE always using Batch G.D. (See Glossary)

- Resolution for:
  
  > Multivariate Regression [2].p5-6
  > Linear Regression with one variable (multivariate reg. where n=1) [2].ML.C3
  > Logistic Regression


  2.1.1 Equation

  # Notation note.- theta = θ
  # Notation note.- h_theta = h

  REPEAT
  {
    grad = (1/m) * ( SUM_i=1_to_m ( h( x((i)) ) - y((i)) ) * x_j((i)) )
    θ_j = θ_j - (α * grad)

    # i = 1 .. m: training example
    # j = 0 .. n: feature
    # x_0((i)) = 1 ∀ i
    # Batch GD: updating θ_j simultaneously# j = 0..n
    
  }


  2.1.2 Vectorized Notation (see glossary for details)

  	# INFO Notation in vectorized notation, uppercase means MATRIX &
  	# lowercase means scalar variable.
	# Exception: y is the solution vector (vector == n x 1 matrix )

  a) Linear Regression
  
     > h_theta(x) = X * θ


     > J(θ) =  (1/2m) (Xθ-y)' (Xθ-y)

       #INFO (Xθ-y)' * (Xθ-y) is just the error calculation, thus (h-y)**2,
       #     in matrix notation (scalar product).


     > grad = (1/m) * X' * (Xθ-y)
       θ = θ - (α * grad)


  a) Logistic Regression
  
     > h_θ(x) = g(Xθ)


     > J(θ) = 1/m ( log(g(Xθ))'y + log(1-g(Xθ))'(1-y) )


     > grad = (1/m) * X' * (g(Xθ)-y)  # logistic vs linear:  g(Xθ) vs Xθ
       θ = θ - (α * grad)


  2.1.3 Speeding up Gradient Descent

  	 - feature scaling technique (GOTO 4.1)
	 - mean normalization technique (GOTO 4.2)
	 - Polynomial Regression technique (GOTO 4.3)


  2.1.4 Debugging Gradient Descent [2].p7
  
  a) α selection for GD

    > Goal is to get the convergence curve as expected (3.c.1)

    > Proven: if α is small enough then J will decrease on every iteration
    > NG suggestion: decreasing α by multiples of 3:
      0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, ...

  b) Numbers of iterations: it is hard to predict ∀ problem.

  c) Correct Convergence Detection

    > Automatic convergence test (the correct in theory)

   	IF J(theta) <= Epsilon in one iteration THEN declare convergence

    > Plot of convergence (the easiest in practice)

   	(plot axis: θX = #iterations ; θY = J)
	Convergence iff curve form is the expected (fast fall - medium fall -
	almost flat)



##------------------------------------------------------------------------------
# 2.2. Normal Equation Method [2].p8
##------------------------------------------------------------------------------

- Mathematical (not AI) method to solve linear regression: finding the OPTIMAL
  theta values without iterations.


  θ = inv(X' * X) * X' * y   #WARNING computation order is θ(n**3)

  #INFO Octave notation: θ = pinv(X) * y 


- GD vs Normal Equation


          GD                vs        Normal Eq.
 ---------------------------|---------------------------
                            |
      Needs α           |          No α
                            |
  Needs many iterations     |        No iterations
                            |
         O(n)               |          O(n**3)           # WARNING key fact
 ---------------------------|---------------------------
 
           ||                             ||
           vv    ((according to Ng))      vv
	   
 ---------------------------|---------------------------	   
 OK for large n (n>=10**4)  |  OK for short n (n<10**4)  # CONCLUSION !!



##==============================================================================
## 3.- Unsupervised Learning Algorithms
##==============================================================================



##==============================================================================
## 4.- Techniques
##==============================================================================

# 4.1 Feature scaling [2].p6

    Xi = Xi / S    ; S = range(X)

    Used to speed up Gradient Descent Alg.


WARNING Feature scaling when S is close to 0
	(S ~= 0) iff vector feature ~= constant => bad feature => the feature
	must be removed => PROBLEM: S does not exists anymore.

  
# 4.2 Mean Normalization [2].p6

   Xi =  Xi / u   ; u =  mean(X)

   Used to speed up Gradient Descent Alg.


# 4.3 Polynomial Regression [2].p8

   h(x) = θ0 + θ1(x1) ...  ==>  h(x) = θ0 + θ1(x1) +  θ2 * sqrt(x1)

   	where (θ2 * sqrt(x1) ) is created to change the behaviour of the curve
   	to get a bettet fit of the solution (y)

   Used to improve the hypothesis function (h)

   INFO    d: polynomial degree of h(x)


# 4.4 Advanced Optimization [2].14, [3]video6.6_time=5:45

  - GD, L-BFG [4.3], BFGS [4.4], Conjugate gradient method [4.5]

  WARNING Used in [3] with Octave code

  a) Input required for the algorithms: code for 'grad', and code for J(θ)

  b) Plus 
     - Not needed to understand how they work, just use it (Octave libs).
     - α is calculated automatically.
     - Faster than manual algorithms.

  c) Minus
     - Complex than  manual algorithms.
     


##==============================================================================
# 5.- Regularization (solving the over-fitting problem)
##==============================================================================

# 5.1. Overfitting Problem (high variance - related to precision) [2].p17

  - Detection: h(x) match the training set almost perfectly.

  - Consequences: h(x) bad generalization.
  
  - Causes & solutions:

    i) Cause: too many features (n >> m). This means that some features are not
       representative to find the solution.

       Solution (-n): reduction of the number of features; manually or
       automatically (Model Selection algorithm)
       
       Solution (+m): add more training examples.
       
    ii) Cause: all the features are useful to find the solution, but the cost
    	function (J) is too much complex.

	Solution: Regularization


    WARNING First Mandatory action to get a solution: split the data set into:

    	    - training set (get Theta values)

	    - cross validation set (get λ, α, d, ...)

	    - test set (check the goodness of the algorithm)


# 5.2. Underfitting Problem (high bias - related to exactitude) [2].p17

  - Detection: h(x) does not fit the training set.

  - Consequences: h(x) bad generalization.
  
  - Causes & solutions:

    i) Cause: very few features (n << m). 

       Solution (+ n): add features.
       
    ii) Cause: cost function (J) is too much simple (i.e. h(x) = cte = 2)

    	Solution (+ d): increase the complexity of J (i.e. Polynomial Regression
    	technique)


# 5.3. Regularization [2].p17-20

  WHY Solution to overfitting problem caused by an excesive complex cost
      function, and when all the features are usefull to find the solution.

  HOW keep all the features but reduce the weight of some/every feature by
      incresing their cost.

  i) Decrease λ -> to fix high bias problem
  
  ii) Increase λ -> to fix high variance problem

  

##==============================================================================
# 6.- Advice for applying Machine Learning [2].page29-32
##==============================================================================

#INFO Notation: 'd' is the polynomial degree of h(x)


# 6.1 Is h(x) OK? - Evaluating the hypothesis function

  Overfitting => split the data in different sets: training, cv, test

  a) Error sets:
     - Training Error: X_train, y_train, m_train)
     - Cross validation Error: X_cv, y_cv, m_cv)
     - Test Error: X_test, y_test, m_test)

  b) Test Steps:
  
     i) Learn θ

     ii) Get J_train & J_vc (WITHOUT REGULARIZATION) to paint the learning
     	 curves to detect bias/variance errors.

     iii) Compute test set error (X_test, y_test, m_test), WITHOUT
     	  REGULARIZATION.

     	  Linear Error:   error(h,y) = 1/2m ∑((h-y)**2)

	  Logistic Error: error(h,y) = 1/2m ∑((h-y)**2)
	  	   	    OR
	  	   	  error(h,y) = miss-classification error (GOTO 1.2.4)

     iv) Compute the "Average Test Error" = 1/m ∑err(h,y)
     	     (X_test, y_test, m_test)


# 6.2 Are the data sets OK? - Model selection & train/cv/test sets

  We need to split the data set into three different sets:

  - training set (60%): used to optimize h (get Theta values)
  
  - cross validation set (20%): used to optimize other training parameters
    (λ, α, d, ...)

  - test set (20%): used to check the goodness of the solution
  

  WHY? Because J_training has been optimized for the training set -> J_training
       bad generalization.

       And because J_cv has been optimized for (e.g.) 'd' -> J_cv bad
       generalization.

       But the test set has not been used yet -> J_test good means that h(x)
       will have good generalization


  Goal: selection of the best polynomial degree for h(x)

  Steps:

  i)   Training set: ∀ 'd', min J_train = 1/2m SUM((h-y)**2)

  ii)  Cross Validation set:  ∀ 'd', min J_cv

  iii) Pick 'd' where J_cv is minimum

  iv)  Estimate generalization error for the test set: J_test(O((d_min)))


# 6.3 Bias/Variance

  INFO High variance => over-fitting problem
  INFO High bias => under-fitting problem


# 6.3.1 Trade-off intuition 

  i) Complex Model (high polynomial degree) ->
     -> very sensitive to data ->
     -> highly affected by changes in X (input)

     => high variance & low bias


  i) Simple Model -> rigid -> lowly affected by changes in X (input)

     => low variance & high bias


# 6.3.2 Is 'd' OK? - Learning curves: 'd' selection

  - Plot (OX is 'd'; OY is J(theta))

    INFO J result high: means J value is distant to 0 

    INFO J result low: means J value is close to 0

  - Check the plot values of J_train & J_cv to check/find 'd'

  For any point in the plot, this is the meaning:
  
  case High bias: if (J_train ~= J_cv) and (both of them are high)

  case High variance: if (J_cv >> J_train ) and (J_train low)

  case optimal value for 'd': the lowest point for both J_train & J_cv where
       	       	     	      (J_train ~= J_cv)


# 6.3.3 Is 'm' OK? - Learning curves: 'm' selection

  - Plot (OX is 'm'; OY is J(theta))

  - Check the plot values of J_train & J_cv to check/find 'm'.

  For any point in the plot, this is the meaning:
  
  case High bias: if (J_train ~= J_cv) and (both of them are high)

  case High variance: if (J_cv >> J_train ) and (J_train low)


# 6.3.4 Is λ OK? - Regularization & Bias/Variance: selecting λ


# 6.3.5 The decision process

  a) Fixing high variance problem (over-fitting)

     ... by simplifying the model

     i)   (+l) Increase λ (in regularization).

     ii)  (-n) Remove some (non representatives) features.

     ... by adding training examples

     iii) (+m) Add training examples.


  b) Fixing high bias problem (under-fitting)
  
     ... by increasing the complexity of the model

     i)   (-l) Decrease λ (in regularization).

     ii)  (+n) Add features.

     iii) (+d) Add polynomial features.


     WARNING Adding training examples (+m) does not fix high bias.
     

# 6.4 Neural Networks Diagnosis


##==============================================================================
# 7.- Machine Learning systems design [2].page33 FIXME_TODO
##==============================================================================

7.1 Error analysis:

- Recommended approach to solve a ML problem

  a) Start with a quick and dirty algorithm.
     > Test this alg. on the cross validation (cv) data set

  b) Plot learning curves to decide:
     > more data (+m) ?
     > more features (+n) ?
     > ...

  c) Error analysis: MANUALLY examine the errors on the cross validation (cv)
     data set to find systematic trends.

- Numerical evaluation: set a measure of your algorithm (%error, accuracy,
  ...), to see the results quickly.


7.2 Error metrics for skewed classes: apply the Precision-Recall trade-off [4.1]

    - (Type of) Error Matrix

                                      True  class
		
                   |          1             |          0              |
                ---|--------------------------------------------------| 
                   |                        |                         |
    Predicted   1  |      True Positive     |   (FP) False Positive   |
                   |                        |                         |
                ---|--------------------------------------------------|
     class         |                        |                         |
                0  |   (FN) False Negative  |      True Negative      |
                   |                        |                         |
                ---|--------------------------------------------------|



    a) Precision =  True Positive / (TP + FP)    # ( TP / ∑ predicted 1s)

    b) Recall =   True Positive / (TP + FN)      # ( TP / ∑ true 1s)

    c) Accuracy =  ∑ true / ∑ total = (TP + TN) / (TP + TN + FP + FN)

    d) Numerical evaluation: f1score = (2 * P * R) / (P + R)


HINT    Train P & R on the cv_set
                                          | inc threshold => inc P  &  dec R 
                                          |
HINT	Predict 1  if h(x) >= threshold  <
                                          | 
					  | dec theshold  => dec P  &  inc R
					  

WARNING If we want to assure recall (i.e. to detect the max. number of skewed),
	then the precision tends to fall.

WARNING Accuracy is a bad index to evaluate skewed classes (always high)


7.3 How much data should we train?

    a) Choose the correct features (X set) to have enough information:

       Given X, would a human expert predict y?

    b) First: get a low bias algorithm.
       Second: reduce overfiting and increase the accuracy of the training set.



##==============================================================================
## Hints
##==============================================================================

HINT (Batch) Gradient Descent algorithm ALWAYS converge to GLOBAL minimum for
     linear regression problems. [2].ML.C3


HINT (Batch) Gradient Descent algorithm scales better than the numerical method
     (Normal Equations Method), for large training sets (n>10000)


HINT Logistic Regression Cost Function (sigma) is convex => Gradient Descent
     algorithm ALWAYS converge to GLOBAL minimum

HINT Logistic Regression: class probabilities are extremely useful in a practice

HINT Why train/cv/test sets: (GOTO 6.2)


##==============================================================================
## Warnings
##==============================================================================

WARNING Feature scaling when S is close to 0
	(S ~= 0) iff vector feature ~= constant => bad feature => the feature
	must be removed => PROBLEM: S does not exists anymore.


WARNING Multiple Regression vs Multivariate Regression
	Multiple Regression:      y = f(X1, .., Xn)
	Multivariate Regression:  f(Y1, .., Yn) = f(X1, .., Xn)


WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ



##==============================================================================
## Annex.- Maths Review
##==============================================================================



##==============================================================================
## Annex.- Linear Algebra Review
##==============================================================================



##==============================================================================
## Annex.- Glossary 
##==============================================================================

A


B

- Batch Gradient Descent algorithm: for every iteration step of the GD
  algorithm, we SIMULTANEOUSLY use (update) the entire training set.


C

- Classification Problem: to predict the actual DISCRETE valued output
  (i.e. {yes, no})
  
- Cost function: function to get the learning algorithm result.
  i.e. in linear regression this is the function to minimize

- cv: cross validation set


G

- Gaussian Distribution (Normal Distribution) [2].page.ML_C5

  x ~ N(μ,σ2)

  o: desviación típica
  o**2: varianza


L

- Labeled data: data for which we know its value, thus, given a X data set, it
  is labeled iff we also know Y.
  Used to evaluate the system: cv_set and test_set.


N

- Non invertibility Problem [2].p9: Matrix non invertible -> can not be used to
  GD calculation.
  Cause -> Solution: feature redundancy -> remove the dependent feature
  Cause -> Solution: (n >= m) -> remove some features or regularization.
  INFO In Octave, pinv(X) ALWAYS calculates the inverse matrix of X.

- Normal Equation Method: mathematical (not AI) method to solve linear
  regression. This method is suggested for low size training sets.


O

- Ordinary Least Squares (OLS): method for estimating the unknown parameters in
  a (linear) regression problem


P

- Precision: see 4.4


R

- Recall: see 4.4

- Regression Problem: predict the actual CONTINUOUS valued output.


S

- Sigmoid Function: "g(z) = 1 / (1 +  e**(-z))"   [2].ML.C5, [4.2]
  Cost function used to solve logistic (classification) regression problems.
  WARNING case 'z -> ∞' (e.g. θ'x very big): logistic regression has no solution
	Explanation: z -> ∞ => h=1 => log(1-h) = ∞
	Solution: 1) try normalization on X; 2) try changing initial θ


- Skewed classes: classes that are very rare in the data set.
  (e.g) rain vs not rain -> 50% / 50% -> no skewed
  	cancer vs not cancer -> 0.05% / 99.5% -> cancer is a skewed class
  Skewed classes can be evaluated using the Precision/Recall technique (see 4.4)
  WARNING Accuracy is a bad index to evaluate skewed classes (always high)

- Supervised Learning (Algorithms): for every example of the data set, we are
  provided with the "correct answer" to predict. Thus, the training example
  sets are provided to the algorithm.


U

- Unsupervised Learning (Algorithms): neither the training set, nor the possible
  solution are provided to the algorithm. The algorithm itself make its own
  conclusions as a result to an input; and later the human engineer will study
  this conclusions.


V

- Vectorized Notation (or Matrix Notation): used to optimize the speed of the
  calculations.
  Relies on the mathematical software libraries used: using the library's
  matrix operations instead of manual programming using "for loops".
  The speed up can be in order of hundreds (empirically tested)


##==============================================================================
## References
##==============================================================================

[1] Machine Learning course - U. Stanford (Andrew Ng)

[2] Notest at the ML (paper) notebook.

[3] Machine Learning course - U.Washington


[4] Other Web references

[4.1] Precision/Recall - https://en.wikipedia.org/wiki/Precision_and_recall
[4.2] Sigmoid function - https://en.wikipedia.org/wiki/Sigmoid_function
[4.3] L-BFGS algorithm - https://es.wikipedia.org/wiki/L-BFGS
[4.4] BFGS algorithm - https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm
[4.5] Conjugate gradient method - https://en.wikipedia.org/wiki/Conjugate_gradient_method




#######################################
# http://www.rapidtables.com/math/symbols/Basic_Math_Symbols.htm
#######################################
# ∀
# ∏
# ∑
#######################################
# ∃
# ∈
# ∉
# ∩
# ∧
# ε
# ∇
#######################################
# α
# β
# λ
# θ theta
# δ delta
# π
# σ sigma
# ∇ gradient
# N(μ,σ2)
#######################################
# ∝
# ∞
# √
# ≈
# ≤
# ≥
# ±
# ⊂
# ≡
#######################################
